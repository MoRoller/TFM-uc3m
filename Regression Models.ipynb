{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdee5c-e56b-43ce-80fb-560dce5c23a4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0ce080-7d2e-4622-819d-1c354482cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import sparse\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8987f5-066f-47d5-aa80-265a5ee4f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cross_val = KFold(n_splits=5, shuffle = True, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a78a05c-b6e2-473f-9a54-2d8c6ea8ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "np.int = int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d20e0b-b13e-4220-af79-b7ba27893a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('G:/Meine Ablage/Studium/03 UC3M/Thesis/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad95e8c-2f1f-48b3-a9aa-1c8f11acfde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_valence: (22697,)\n",
      "y_arousal: (22697,)\n",
      "TF-IDF: (22697, 659)\n",
      "Word2Vec custom: (22697, 300)\n",
      "Word2Vec pretrained: (22697, 300)\n",
      "Word2Vec pretrained TF-IDF: (22697, 300)\n",
      "Word2Vec custom TF-IDF: (22697, 300)\n",
      "Doc2Vec: (22697, 300)\n",
      "GloVe pretrained: (22697, 300)\n",
      "GloVe custom: (22697, 300)\n",
      "BERT: (22697, 768)\n",
      "BERT CLS: (22697, 768)\n",
      "BERT MeanPooling: (22697, 768)\n",
      "DistillBERT CLS: (22697, 768)\n",
      "DistillBERT MeanPooling: (22697, 768)\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# load y from local files\n",
    "y_train_valence = np.load('y_train_valence.npy')\n",
    "y_train_arousal = np.load('y_train_arousal.npy')\n",
    "y_test_valence = np.load('y_test_valence.npy')\n",
    "y_test_arousal = np.load('y_test_arousal.npy')\n",
    "\n",
    "print(\"y_valence:\", y_train_valence.shape)\n",
    "print(\"y_arousal:\", y_train_valence.shape)\n",
    "\n",
    "# load embeddings from local files\n",
    "##################################################################################\n",
    "# TF-IDF\n",
    "X_train_tfidf = sparse.load_npz(os.path.join('TF-IDF', 'X_train_tfidf.npz'))\n",
    "X_test_tfidf = sparse.load_npz(os.path.join('TF-IDF', 'X_test_tfidf.npz'))\n",
    "print(\"TF-IDF:\", X_train_tfidf.shape)\n",
    "\n",
    "##################################################################################\n",
    "# Word2Vec\n",
    "X_train_Word2Vec_custom = np.load(os.path.join('Word2Vec', 'X_train_Word2Vec_custom.npy'))\n",
    "X_test_Word2Vec_custom = np.load(os.path.join('Word2Vec', 'X_test_Word2Vec_custom.npy'))\n",
    "print(\"Word2Vec custom:\", X_train_Word2Vec_custom.shape)\n",
    "\n",
    "X_train_Word2Vec_pretrained = np.load(os.path.join('Word2Vec', 'X_train_Word2Vec_pretrained.npy'))\n",
    "X_test_Word2Vec_pretrained = np.load(os.path.join('Word2Vec', 'X_test_Word2Vec_pretrained.npy'))\n",
    "print(\"Word2Vec pretrained:\", X_train_Word2Vec_pretrained.shape)\n",
    "\n",
    "# Word2Vec + TF-IDF\n",
    "X_train_Word2Vec_pretrained_tfidf = np.load(os.path.join('Word2Vec', 'X_train_Word2Vec_pretrained_tfidf.npy'))\n",
    "X_test_Word2Vec_pretrained_tfidf = np.load(os.path.join('Word2Vec', 'X_test_Word2Vec_pretrained_tfidf.npy'))\n",
    "print(\"Word2Vec pretrained TF-IDF:\", X_train_Word2Vec_pretrained_tfidf.shape)\n",
    "\n",
    "X_train_Word2Vec_custom_tfidf = np.load(os.path.join('Word2Vec', 'X_train_Word2Vec_custom_tfidf.npy'))\n",
    "X_test_Word2Vec_custom_tfidf = np.load(os.path.join('Word2Vec', 'X_test_Word2Vec_custom_tfidf.npy'))\n",
    "print(\"Word2Vec custom TF-IDF:\", X_train_Word2Vec_custom.shape)\n",
    "\n",
    "##################################################################################\n",
    "# Doc2Vec\n",
    "X_train_Doc2Vec = np.load(os.path.join('Doc2Vec', 'X_train_Doc2Vec.npy'))\n",
    "X_test_Doc2Vec = np.load(os.path.join('Doc2Vec', 'X_test_Doc2Vec.npy'))\n",
    "print(\"Doc2Vec:\", X_train_Doc2Vec.shape)\n",
    "\n",
    "##################################################################################\n",
    "# GloVe\n",
    "X_train_GloVe_pretrained = np.load(os.path.join('GloVe', 'X_train_GloVe_pretrained.npy'))\n",
    "X_test_GloVe_pretrained = np.load(os.path.join('GloVe', 'X_test_GloVe_pretrained.npy'))\n",
    "print(\"GloVe pretrained:\", X_train_GloVe_pretrained.shape)\n",
    "\n",
    "X_train_GloVe_custom = np.load(os.path.join('GloVe', 'X_train_GloVe_custom.npy'))\n",
    "X_test_GloVe_custom = np.load(os.path.join('GloVe', 'X_test_GloVe_custom.npy'))\n",
    "print(\"GloVe custom:\", X_train_GloVe_custom.shape)\n",
    "\n",
    "##################################################################################\n",
    "# BERT Pooler Outputs\n",
    "X_train_BERT = torch.load(os.path.join('BERT', 'BERT_train_pooler_outputs.pt')).numpy()\n",
    "X_test_BERT = torch.load(os.path.join('BERT', 'BERT_test_pooler_outputs.pt')).numpy()\n",
    "print(\"BERT:\", X_train_BERT.shape)\n",
    "\n",
    "# BERT CLS\n",
    "X_train_BERT_CLS = np.load(os.path.join('BERT', 'X_train_BERT_CLS.npy'))\n",
    "X_test_BERT_CLS = np.load(os.path.join('BERT', 'X_test_BERT_CLS.npy'))\n",
    "print(\"BERT CLS:\", X_train_BERT_CLS.shape)\n",
    "\n",
    "# BERT MeanPooling\n",
    "X_train_BERT_MeanPooling = np.load(os.path.join('BERT', 'X_train_BERT_MeanPooling.npy'))\n",
    "X_test_BERT_MeanPooling = np.load(os.path.join('BERT', 'X_test_BERT_MeanPooling.npy'))\n",
    "print(\"BERT MeanPooling:\", X_train_BERT_MeanPooling.shape)\n",
    "\n",
    "##################################################################################\n",
    "# DistillBERT CLS\n",
    "X_train_DistillBERT_CLS = np.load(os.path.join('DistillBERT', 'X_train_DistillBERT_CLS.npy'))\n",
    "X_test_DistillBERT_CLS = np.load(os.path.join('DistillBERT', 'X_test_DistillBERT_CLS.npy'))\n",
    "print(\"DistillBERT CLS:\", X_train_DistillBERT_CLS.shape)\n",
    "\n",
    "# DistillBERT MeanPooling\n",
    "X_train_DistillBERT_MeanPooling = np.load(os.path.join('DistillBERT', 'X_train_DistillBERT_MeanPooling.npy'))\n",
    "X_test_DistillBERT_MeanPooling = np.load(os.path.join('DistillBERT', 'X_test_DistillBERT_MeanPooling.npy'))\n",
    "print(\"DistillBERT MeanPooling:\", X_train_DistillBERT_MeanPooling.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c5c17-333f-431a-b122-6d64042e2b7a",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1f003ea5-3cc3-4848-8713-d55e740c3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def SGDR_Regressor(X_train_, y_train_, X_test_, y_test_, param_grid_):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    param_grid = param_grid_\n",
    "    \n",
    "    warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n",
    "    SGDR_opt = BayesSearchCV(\n",
    "        SGDRegressor(random_state=18),\n",
    "        search_spaces=param_grid_, n_iter=50, cv=cross_val, scoring='neg_mean_squared_error', n_jobs=4, verbose=False, random_state=18)\n",
    "    SGDR_opt.fit(X_train_, y_train_)\n",
    "    \n",
    "    t1 = time.time()-t0\n",
    "    print(f'Duration: {round(t1,2)} s')\n",
    "\n",
    "    print(f'{SGDR_opt.best_params_=}')\n",
    "    print(f'{SGDR_opt.best_score_=}')\n",
    "\n",
    "    # predict test\n",
    "    predictions = SGDR_opt.best_estimator_.predict(X_test_)\n",
    "    MSE_test = mean_squared_error(y_test_, predictions)\n",
    "    print(f'MSE Test: {round(MSE_test,4)}')\n",
    "    \n",
    "    return SGDR_opt, predictions, MSE_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "496cc8be-491f-4b53-823a-b5b904488997",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_iter': Integer(50,1000),\n",
    "    'tol': [1e-6],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': Real(1e-5, 1e0), \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5709b-a275-459f-a50f-2fb33fe34a2b",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cd78d0f-c098-40f7-9727-45ff7517d9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 162.7 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.0031855101217521803), ('max_iter', 456), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05810187378369895\n",
      "MSE Test: 0.0588\n",
      "---------------------------------------------------------\n",
      "Duration: 172.18 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 1000), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04957876978345284\n",
      "MSE Test: 0.0489\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_SGDR_valence_tfidf, predictions_SGDR_valence_tfidf, MSE_SGDR_valence_tfidf = SGDR_Regressor(\n",
    "    X_train_tfidf, y_train_valence, X_test_tfidf, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_tfidf, predictions_SGDR_arousal_tfidf, MSE_SGDR_arousal_tfidf = SGDR_Regressor(\n",
    "    X_train_tfidf, y_train_arousal, X_test_tfidf, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b1773-deda-4787-aad6-934e70a0c9a3",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e037c2-9d5c-4c19-9a91-96a94e703a08",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93c83450-cfc7-4005-83be-0d9b5e9ed33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 197.47 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 1000), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.057340986586998835\n",
      "MSE Test: 0.0577\n",
      "---------------------------------------------------------\n",
      "Duration: 191.93 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 905), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.049027379957977346\n",
      "MSE Test: 0.0481\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_Word2Vec_pretrained, predictions_SGDR_valence_Word2Vec_pretrained, MSE_SGDR_valence_Word2Vec_pretrained = SGDR_Regressor(\n",
    "    X_train_Word2Vec_pretrained, y_train_valence, X_test_Word2Vec_pretrained, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_Word2Vec_pretrained, predictions_SGDR_arousal_Word2Vec_pretrained, MSE_SGDR_arousal_Word2Vec_pretrained = SGDR_Regressor(\n",
    "    X_train_Word2Vec_pretrained, y_train_arousal, X_test_Word2Vec_pretrained, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5a367d3-1b6f-4124-9bd9-a301f583d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 211.17 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 7.899592544633248e-05), ('max_iter', 402), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.059184990501516335\n",
      "MSE Test: 0.0611\n",
      "---------------------------------------------------------\n",
      "Duration: 204.4 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 7.899592544633248e-05), ('max_iter', 402), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05234155625570027\n",
      "MSE Test: 0.0543\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_Word2Vec_pretrained_tfidf, predictions_SGDR_valence_Word2Vec_pretrained_tfidf, MSE_SGDR_valence_Word2Vec_pretrained_tfidf = SGDR_Regressor(\n",
    "    X_train_Word2Vec_pretrained_tfidf, y_train_valence, X_test_Word2Vec_pretrained_tfidf, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_Word2Vec_pretrained_tfidf, predictions_SGDR_arousal_Word2Vec_pretrained_tfidf, MSE_SGDR_arousal_Word2Vec_pretrained_tfidf = SGDR_Regressor(\n",
    "    X_train_Word2Vec_pretrained_tfidf, y_train_arousal, X_test_Word2Vec_pretrained_tfidf, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6b0a1-45c5-46cb-938e-e91f91ca568f",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "075f19df-d7e8-42b0-9333-e6d0976ff34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 159.15 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.00012358063208553572), ('max_iter', 875), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05693154474639951\n",
      "MSE Test: 0.0575\n",
      "---------------------------------------------------------\n",
      "Duration: 175.97 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.00021884868849339834), ('max_iter', 190), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04855923635741496\n",
      "MSE Test: 0.048\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_Word2Vec_custom, predictions_SGDR_valence_Word2Vec_custom, MSE_SGDR_valence_Word2Vec_custom = SGDR_Regressor(\n",
    "    X_train_Word2Vec_custom, y_train_valence, X_test_Word2Vec_custom, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_Word2Vec_custom, predictions_SGDR_arousal_Word2Vec_custom, MSE_SGDR_arousal_Word2Vec_custom = SGDR_Regressor(\n",
    "    X_train_Word2Vec_custom, y_train_arousal, X_test_Word2Vec_custom, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1eb10360-76d3-42c5-861d-1d1ff71a8043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 214.83 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 50), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05898598889346679\n",
      "MSE Test: 0.0682\n",
      "---------------------------------------------------------\n",
      "Duration: 237.63 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 1000), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05189040990292124\n",
      "MSE Test: 0.0903\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_custom_tfidf, predictions_SGDR_valence_Word2Vec_custom_tfidf, MSE_SGDR_valence_Word2Vec_custom_tfidf = SGDR_Regressor(\n",
    "    X_train_Word2Vec_custom_tfidf, y_train_valence, X_test_Word2Vec_custom_tfidf, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_Word2Vec_custom_tfidf, predictions_SGDR_arousal_Word2Vec_custom_tfidf, MSE_SGDR_arousal_Word2Vec_custom_tfidf = SGDR_Regressor(\n",
    "    X_train_Word2Vec_custom_tfidf, y_train_arousal, X_test_Word2Vec_custom_tfidf, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e527d8b-e481-4139-b6ff-1edb734c4ed1",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b4b9e57-e5bd-48a1-9890-ffb2a81328d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 165.98 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 7.899592544633248e-05), ('max_iter', 402), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05803025563403212\n",
      "MSE Test: 0.0597\n",
      "---------------------------------------------------------\n",
      "Duration: 189.75 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 7.899592544633248e-05), ('max_iter', 402), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.052096845797540516\n",
      "MSE Test: 0.0534\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_SGDR_valence_Doc2Vec, predictions_SGDR_valence_Doc2Vec, MSE_SGDR_valence_Doc2Vec = SGDR_Regressor(\n",
    "    X_train_Doc2Vec, y_train_valence, X_test_Doc2Vec, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_Doc2Vec, predictions_SGDR_arousal_Doc2Vec, MSE_SGDR_arousal_Doc2Vec = SGDR_Regressor(\n",
    "    X_train_Doc2Vec, y_train_arousal, X_test_Doc2Vec, y_test_arousal, param_grid_=param_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e50c68-0839-4c69-ab8e-962d2169aab8",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d05b3-5060-435b-b23a-2ed0f5b32b69",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f837efc-4049-47cf-86f5-98ec493c314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 180.82 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 50), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.056923861849053715\n",
      "MSE Test: 0.0574\n",
      "---------------------------------------------------------\n",
      "Duration: 217.63 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 1000), ('penalty', 'l1'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.048326842124732525\n",
      "MSE Test: 0.0476\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_SGDR_valence_GloVe_pretrained, predictions_SGDR_valence_GloVe_pretrained, MSE_SGDR_valence_GloVe_pretrained = SGDR_Regressor(\n",
    "    X_train_GloVe_pretrained, y_train_valence, X_test_GloVe_pretrained, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_GloVe_pretrained, predictions_SGDR_arousal_GloVe_pretrained, MSE_SGDR_arousal_GloVe_pretrained = SGDR_Regressor(\n",
    "    X_train_GloVe_pretrained, y_train_arousal, X_test_GloVe_pretrained, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a7f28-7b68-4049-bfb9-7eca77b05d7b",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02800515-21f3-4157-a1c8-5dbf31b2316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 165.57 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 84), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05770124868879808\n",
      "MSE Test: 0.058\n",
      "---------------------------------------------------------\n",
      "Duration: 164.1 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 835), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04986151498175142\n",
      "MSE Test: 0.0493\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_SGDR_valence_GloVe_custom, predictions_SGDR_valence_GloVe_custom, MSE_SGDR_valence_GloVe_custom = SGDR_Regressor(\n",
    "    X_train_GloVe_custom, y_train_valence, X_test_GloVe_custom, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_GloVe_custom, predictions_SGDR_arousal_GloVe_custom, MSE_SGDR_arousal_GloVe_custom = SGDR_Regressor(\n",
    "    X_train_GloVe_custom, y_train_arousal, X_test_GloVe_custom, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a7b75-24b7-4924-bfae-1f63f6f18d4d",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413896d-0c7e-4368-88ca-12e3a77dd2fb",
   "metadata": {},
   "source": [
    "**Pooler Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30238e71-bc23-46f8-9f08-869933b7fd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 359.91 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.000917522055172836), ('max_iter', 70), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05719172100021698\n",
      "MSE Test: 0.058\n",
      "---------------------------------------------------------\n",
      "Duration: 371.14 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 8.550716741921622e-05), ('max_iter', 179), ('penalty', 'l1'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04722354367893472\n",
      "MSE Test: 0.0473\n"
     ]
    }
   ],
   "source": [
    "# Pooler Outputs\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_BERT, predictions_SGDR_valence_BERT, MSE_SGDR_valence_BERT = SGDR_Regressor(\n",
    "    X_train_BERT, y_train_valence, X_test_BERT, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_BERT, predictions_SGDR_arousal_BERT, MSE_SGDR_arousal_BERT = SGDR_Regressor(\n",
    "    X_train_BERT, y_train_arousal, X_test_BERT, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9aff5-3483-42c6-a70a-96a638d64e9f",
   "metadata": {},
   "source": [
    "**CLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e66d5af-a198-4d95-afbc-1e447757aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 346.61 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.004220398176561813), ('max_iter', 965), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.0571334775341274\n",
      "MSE Test: 0.0577\n",
      "---------------------------------------------------------\n",
      "Duration: 371.91 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.0002363099907671545), ('max_iter', 109), ('penalty', 'l1'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04706107800965008\n",
      "MSE Test: 0.046\n"
     ]
    }
   ],
   "source": [
    "# CLS\n",
    "# Valence\n",
    "model_SGDR_valence_BERT_CLS, predictions_SGDR_valence_BERT_CLS, MSE_SGDR_valence_BERT_CLS = SGDR_Regressor(\n",
    "    X_train_BERT_CLS, y_train_valence, X_test_BERT_CLS, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_SGDR_arousal_BERT_CLS, predictions_SGDR_arousal_BERT_CLS, MSE_SGDR_arousal_BERT_CLS = SGDR_Regressor(\n",
    "    X_train_BERT_CLS, y_train_arousal, X_test_BERT_CLS, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915d237-611c-41c5-a5a0-47ecc0e78a44",
   "metadata": {},
   "source": [
    "**Mean Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a566b671-9bfb-4dea-be14-9d2a71ba9179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 394.23 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 8.550716741921622e-05), ('max_iter', 179), ('penalty', 'l1'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05743967449982632\n",
      "MSE Test: 0.0574\n",
      "---------------------------------------------------------\n",
      "Duration: 372.64 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.000412620738440573), ('max_iter', 987), ('penalty', 'l1'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.046949394931145784\n",
      "MSE Test: 0.0463\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_BERT_MeanPooling, predictions_SGDR_valence_BERT_MeanPooling, MSE_SGDR_valence_BERT_MeanPooling = SGDR_Regressor(\n",
    "    X_train_BERT_MeanPooling, y_train_valence, X_test_BERT_MeanPooling, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Arousal\n",
    "model_SGDR_arousal_BERT_MeanPooling, predictions_SGDR_arousal_BERT_MeanPooling, MSE_SGDR_arousal_BERT_MeanPooling = SGDR_Regressor(\n",
    "    X_train_BERT_MeanPooling, y_train_arousal, X_test_BERT_MeanPooling, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8feb650-ceb6-465d-9944-430ae5eb9f85",
   "metadata": {},
   "source": [
    "## DistillBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1de53-8124-471b-b255-7e9ff90583fd",
   "metadata": {},
   "source": [
    "**CLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59a5659a-ce26-4433-9bd2-3297183c5936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 320.73 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 1000), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05745548654804346\n",
      "MSE Test: 0.0568\n",
      "---------------------------------------------------------\n",
      "Duration: 371.37 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.00012358063208553572), ('max_iter', 875), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04587249617765428\n",
      "MSE Test: 0.0448\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_SGDR_valence_DistillBERT_CLS, predictions_SGDR_valence_DistillBERT_CLS, MSE_SGDR_valence_DistillBERT_CLS = SGDR_Regressor(\n",
    "    X_train_DistillBERT_CLS, y_train_valence, X_test_DistillBERT_CLS, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Arousal\n",
    "model_SGDR_arousal_DistillBERT_CLS, predictions_SGDR_arousal_DistillBERT_CLS, MSE_SGDR_arousal_DistillBERT_CLS = SGDR_Regressor(\n",
    "    X_train_DistillBERT_CLS, y_train_arousal, X_test_DistillBERT_CLS, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7425f-7fcd-4637-96c1-68914ececf24",
   "metadata": {},
   "source": [
    "**Mean Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a60f402-2f40-408d-a746-9998ce883078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 408.91 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 8.550716741921622e-05), ('max_iter', 179), ('penalty', 'l1'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05630120554118826\n",
      "MSE Test: 0.0564\n",
      "---------------------------------------------------------\n",
      "Duration: 366.78 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 50), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.045599817102286826\n",
      "MSE Test: 0.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "# Valence\n",
    "model_SGDR_valence_DistillBERT_MeanPooling, predictions_SGDR_valence_DistillBERT_MeanPooling, MSE_SGDR_valence_DistillBERT_MeanPooling = SGDR_Regressor(\n",
    "    X_train_DistillBERT_MeanPooling, y_train_valence, X_test_DistillBERT_MeanPooling, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Arousal\n",
    "model_SGDR_arousal_DistillBERT_MeanPooling, predictions_SGDR_arousal_DistillBERT_MeanPooling, MSE_SGDR_arousal_DistillBERT_MeanPooling = SGDR_Regressor(\n",
    "    X_train_DistillBERT_MeanPooling, y_train_arousal, X_test_DistillBERT_MeanPooling, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25598c0a-b088-4ff0-a8f0-30b26684784b",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f340017-2544-46da-ba91-d639f937bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "def GradientBoostedTree(X_train_, y_train_, X_test_, y_test_, param_grid_):\n",
    "    t0 = time.time()\n",
    "\n",
    "    warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n",
    "    model_opt = BayesSearchCV(\n",
    "        HistGradientBoostingRegressor(random_state=18),\n",
    "        search_spaces=param_grid_, n_iter=50, cv=cross_val, scoring='neg_mean_squared_error', n_jobs=4, verbose=False, random_state=18)\n",
    "    model_opt.fit(X_train_, y_train_)\n",
    "    \n",
    "    t1 = time.time()-t0\n",
    "    print(f'Duration: {round(t1,2)} s')\n",
    "    \n",
    "    print(f'{model_opt.best_params_=}')\n",
    "    print(f'{model_opt.best_score_=}')\n",
    "\n",
    "    predictions = model_opt.best_estimator_.predict(X_test_)\n",
    "    MSE_test = mean_squared_error(y_test_, predictions)\n",
    "    print(f'MSE Test: {round(MSE_test,4)}')\n",
    "    \n",
    "    return model_opt, predictions, MSE_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef37be0-5cd8-4668-834e-1bd4b73dc5be",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3641935f-d289-40f4-a272-efc0e8e02c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_iter': Integer(50,2000),\n",
    "    'max_depth': Integer(10,100),\n",
    "    'learning_rate': Real(1e-3, 1e1),\n",
    "    'l2_regularization': Real(1e-2, 1e1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6a1177b5-9bb1-427b-a945-1636fe428210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 408.81 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.056989063309226304\n",
      "MSE Test: 0.0573\n",
      "---------------------------------------------------------\n",
      "Duration: 452.01 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.047279455468453226\n",
      "MSE Test: 0.0465\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_tfidf, predictions_GBT_valence_tfidf, MSE_GBT_valence_tfidf = GradientBoostedTree(\n",
    "    X_train_tfidf.toarray(), y_train_valence, X_test_tfidf.toarray(), y_test_valence, param_grid)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_GBT_arousal_tfidf, predictions_GBT_arousal_tfidf, MSE_GBT_arousal_tfidf = GradientBoostedTree(\n",
    "    X_train_tfidf.toarray(), y_train_arousal, X_test_tfidf.toarray(), y_test_arousal, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4392bbe-4f38-40c9-8d59-c903f33d1d71",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e868de-202c-4a99-8413-3ffd2690c6ac",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c89622-fd96-4410-8b70-0ee6cbeb2b2e",
   "metadata": {},
   "source": [
    "**Mean Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3fdbae96-916c-4030-9310-ff544a1270e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 293.38 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05811207799979112\n",
      "MSE Test: 0.0581\n",
      "---------------------------------------------------------\n",
      "Duration: 331.43 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04946361908004371\n",
      "MSE Test: 0.0488\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_Word2Vec_pretrained, predictions_GBT_valence_Word2Vec_pretrained, MSE_GBT_valence_Word2Vec_pretrained = GradientBoostedTree(\n",
    "    X_train_Word2Vec_pretrained, y_train_valence, X_test_Word2Vec_pretrained, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_Word2Vec_pretrained, predictions_GBT_arousal_Word2Vec_pretrained, MSE_GBT_arousal_Word2Vec_pretrained = GradientBoostedTree(\n",
    "    X_train_Word2Vec_pretrained, y_train_arousal, X_test_Word2Vec_pretrained, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8fa12-3868-4e19-a5e1-1225e03be038",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7352809e-d5ba-49e3-b345-cbe16b299120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 284.22 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05952322103384152\n",
      "MSE Test: 0.0614\n",
      "---------------------------------------------------------\n",
      "Duration: 322.07 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.051964641308178815\n",
      "MSE Test: 0.0556\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_Word2Vec_pretrained_tfidf, predictions_GBT_valence_Word2Vec_pretrained_tfidf, MSE_GBT_valence_Word2Vec_pretrained_tfidf = GradientBoostedTree(\n",
    "    X_train_Word2Vec_pretrained_tfidf, y_train_valence, X_test_Word2Vec_pretrained_tfidf, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_Word2Vec_pretrained_tfidf, predictions_GBT_arousal_Word2Vec_pretrained_tfidf, MSE_GBT_arousal_Word2Vec_pretrained_tfidf = GradientBoostedTree(\n",
    "    X_train_Word2Vec_pretrained_tfidf, y_train_arousal, X_test_Word2Vec_pretrained_tfidf, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb51f51-65c5-4ef4-adc5-3413bc26ba2a",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83ad76-fae3-43cd-ae6a-89fb4ac3a1c2",
   "metadata": {},
   "source": [
    "**Mean Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a43aa464-aa04-4968-97f1-b15117bd07c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 283.49 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.056882676751853725\n",
      "MSE Test: 0.0567\n",
      "---------------------------------------------------------\n",
      "Duration: 310.26 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04750145477987723\n",
      "MSE Test: 0.0461\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_GBT_valence_Word2Vec_custom, predictions_GBT_valence_Word2Vec_custom, MSE_GBT_valence_Word2Vec_custom = GradientBoostedTree(\n",
    "    X_train_Word2Vec_custom, y_train_valence, X_test_Word2Vec_custom, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_Word2Vec_custom, predictions_GBT_arousal_Word2Vec_custom, MSE_GBT_arousal_Word2Vec_custom = GradientBoostedTree(\n",
    "    X_train_Word2Vec_custom, y_train_arousal, X_test_Word2Vec_custom, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64940d-b44b-42ce-966f-1be699cb470d",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "50b2d46b-2c9a-4505-a288-8766792c3268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 285.95 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 3.7676236273925134), ('learning_rate', 0.23500052224312776), ('max_depth', 42), ('max_iter', 1472)])\n",
      "model_opt.best_score_=-0.05868775670582348\n",
      "MSE Test: 0.066\n",
      "---------------------------------------------------------\n",
      "Duration: 279.47 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05022571798073753\n",
      "MSE Test: 0.0618\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_Word2Vec_custom_tfidf, predictions_GBT_valence_Word2Vec_custom_tfidf, MSE_GBT_valence_Word2Vec_custom_tfidf = GradientBoostedTree(\n",
    "    X_train_Word2Vec_custom_tfidf, y_train_valence, X_test_Word2Vec_custom_tfidf, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_Word2Vec_custom_tfidf, predictions_GBT_arousal_Word2Vec_custom_tfidf, MSE_GBT_arousal_Word2Vec_custom_tfidf = GradientBoostedTree(\n",
    "    X_train_Word2Vec_custom_tfidf, y_train_arousal, X_test_Word2Vec_custom_tfidf, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7026e-11b5-47f4-b31f-7aa40001b902",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51ddbcc3-912b-4261-b60a-efedbe34b979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 289.81 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05754555085899551\n",
      "MSE Test: 0.0581\n",
      "---------------------------------------------------------\n",
      "Duration: 296.16 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04877633763007466\n",
      "MSE Test: 0.049\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_Doc2Vec, predictions_GBT_valence_Doc2Vec, MSE_GBT_valence_Doc2Vec = GradientBoostedTree(\n",
    "    X_train_Doc2Vec, y_train_valence, X_test_Doc2Vec, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_Doc2Vec, predictions_GBT_arousal_Doc2Vec, MSE_GBT_arousal_Doc2Vec = GradientBoostedTree(\n",
    "    X_train_Doc2Vec, y_train_arousal, X_test_Doc2Vec, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990533c-02c8-4d9a-8209-06e717c670c4",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d3173-f37e-4209-a956-1b16d9a5862f",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "525c5d16-656d-47f7-bc6a-2f1a4470e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 279.06 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05746199190198041\n",
      "MSE Test: 0.0573\n",
      "---------------------------------------------------------\n",
      "Duration: 322.05 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04869815887443634\n",
      "MSE Test: 0.0469\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_GloVe_pretrained, predictions_GBT_valence_GloVe_pretrained, MSE_GBT_valence_GloVe_pretrained = GradientBoostedTree(\n",
    "    X_train_GloVe_pretrained, y_train_valence, X_test_GloVe_pretrained, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_GloVe_pretrained, predictions_GBT_arousal_GloVe_pretrained, MSE_GBT_arousal_GloVe_pretrained = GradientBoostedTree(\n",
    "    X_train_GloVe_pretrained, y_train_arousal, X_test_GloVe_pretrained, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3b3555-93aa-4638-93b7-335570e43bdd",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "da2fdfba-84cb-4f81-809d-dc0561517952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 282.23 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 3.4574374388179687), ('learning_rate', 0.2299180218209334), ('max_depth', 38), ('max_iter', 1453)])\n",
      "model_opt.best_score_=-0.05767695785780327\n",
      "MSE Test: 0.0577\n",
      "---------------------------------------------------------\n",
      "Duration: 310.28 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04852973091360764\n",
      "MSE Test: 0.0476\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_GloVe_custom, predictions_GBT_valence_GloVe_custom, MSE_GBT_valence_GloVe_custom = GradientBoostedTree(\n",
    "    X_train_GloVe_custom, y_train_valence, X_test_GloVe_custom, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_GloVe_custom, predictions_GBT_arousal_GloVe_custom, MSE_GBT_arousal_GloVe_custom = GradientBoostedTree(\n",
    "    X_train_GloVe_custom, y_train_arousal, X_test_GloVe_custom, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a9bd5-6e47-4688-9cef-6abee6bbe68e",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5f5da-90d2-4207-b477-0312b18b8e54",
   "metadata": {},
   "source": [
    "### Pooler Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a6f19ba2-cfe7-41a1-956d-8dfc628bab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 577.33 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05836242369060263\n",
      "MSE Test: 0.0588\n",
      "---------------------------------------------------------\n",
      "Duration: 634.01 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.048805401353988836\n",
      "MSE Test: 0.048\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_BERT, predictions_GBT_valence_BERT, MSE_GBT_valence_BERT = GradientBoostedTree(\n",
    "    X_train_BERT, y_train_valence, X_test_BERT, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_BERT, predictions_GBT_arousal_BERT, MSE_GBT_arousal_BERT = GradientBoostedTree(\n",
    "    X_train_BERT, y_train_arousal, X_test_BERT, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57694c1c-eb03-46f7-a8f4-5e26984f3b33",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c27c25a9-3a11-44aa-9d74-777835de7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 580.16 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.057436613355756595\n",
      "MSE Test: 0.058\n",
      "---------------------------------------------------------\n",
      "Duration: 627.28 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04775130480890928\n",
      "MSE Test: 0.0466\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_BERT_CLS, predictions_GBT_valence_BERT_CLS, MSE_GBT_valence_BERT_CLS = GradientBoostedTree(\n",
    "    X_train_BERT_CLS, y_train_valence, X_test_BERT_CLS, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_BERT_CLS, predictions_GBT_arousal_BERT_CLS, MSE_GBT_arousal_BERT_CLS = GradientBoostedTree(\n",
    "    X_train_BERT_CLS, y_train_arousal, X_test_BERT_CLS, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28df7b-1f83-4b7b-846b-1f0068a4d823",
   "metadata": {},
   "source": [
    "### Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5163095d-4af7-4a8a-b19d-e5d1af5f19a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 579.95 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.05732582280302882\n",
      "MSE Test: 0.0577\n",
      "---------------------------------------------------------\n",
      "Duration: 617.66 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.047545084655370225\n",
      "MSE Test: 0.0461\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_BERT_MeanPooling, predictions_GBT_valence_BERT_MeanPooling, MSE_GBT_valence_BERT_MeanPooling = GradientBoostedTree(\n",
    "    X_train_BERT_MeanPooling, y_train_valence, X_test_BERT_MeanPooling, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_BERT_MeanPooling, predictions_GBT_arousal_BERT_MeanPooling, MSE_GBT_arousal_BERT_MeanPooling = GradientBoostedTree(\n",
    "    X_train_BERT_MeanPooling, y_train_arousal, X_test_BERT_MeanPooling, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68043a3-7e7f-466a-b3c1-28d190323be9",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb01d23-6797-4da7-aabf-4af15c7d7961",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aa1e4b1d-ec3a-4456-9c5a-7bb6e70b6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 575.94 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.056850662292514745\n",
      "MSE Test: 0.0572\n",
      "---------------------------------------------------------\n",
      "Duration: 626.55 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04680287865495596\n",
      "MSE Test: 0.0454\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_DistillBERT_CLS, predictions_GBT_valence_DistillBERT_CLS, MSE_GBT_valence_DistillBERT_CLS = GradientBoostedTree(\n",
    "    X_train_DistillBERT_CLS, y_train_valence, X_test_DistillBERT_CLS, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_DistillBERT_CLS, predictions_GBT_arousal_DistillBERT_CLS, MSE_GBT_arousal_DistillBERT_CLS = GradientBoostedTree(\n",
    "    X_train_DistillBERT_CLS, y_train_arousal, X_test_DistillBERT_CLS, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73013d1e-b084-44a8-99ce-d664ea95af55",
   "metadata": {},
   "source": [
    "### Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2c1298c7-fa40-4f0f-a31f-8ba2dece3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 587.39 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 3.794811181309848), ('learning_rate', 0.22714233433902317), ('max_depth', 40), ('max_iter', 1406)])\n",
      "model_opt.best_score_=-0.05745014304045187\n",
      "MSE Test: 0.0574\n",
      "---------------------------------------------------------\n",
      "Duration: 623.1 s\n",
      "model_opt.best_params_=OrderedDict([('l2_regularization', 2.761729328474661), ('learning_rate', 0.17160775441654405), ('max_depth', 29), ('max_iter', 1724)])\n",
      "model_opt.best_score_=-0.04700776795410779\n",
      "MSE Test: 0.0457\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_GBT_valence_DistillBERT_MeanPooling, predictions_GBT_valence_DistillBERT_MeanPooling, MSE_GBT_valence_DistillBERT_MeanPooling = GradientBoostedTree(\n",
    "    X_train_DistillBERT_MeanPooling, y_train_valence, X_test_DistillBERT_MeanPooling, y_test_valence, param_grid_=param_grid)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_GBT_arousal_DistillBERT_MeanPooling, predictions_GBT_arousal_DistillBERT_MeanPooling, MSE_GBT_arousal_DistillBERT_MeanPooling = GradientBoostedTree(\n",
    "    X_train_DistillBERT_MeanPooling, y_train_arousal, X_test_DistillBERT_MeanPooling, y_test_arousal, param_grid_=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8f2bf711-6d76-408e-90bb-06cab9c63ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scipy.sparse import issparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d3c06026-8d2e-44bd-8a4d-e88d62c6eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN1(X_train_, y_train_, X_test_, y_test_, epochs_=2):\n",
    "    # run for valence + arousal separately (with different y_train_)\n",
    "    set_seeds(18)\n",
    "\n",
    "    if issparse(X_train_):\n",
    "        X_train_ = X_train_.toarray()\n",
    "    if issparse(X_test_):\n",
    "        X_test_ = X_test_.toarray()\n",
    "    # split train into train-train and validation; valence\n",
    "    X_train_NN, X_val_NN, y_train_NN, y_val_NN = train_test_split(X_train_, y_train_, test_size=0.2, random_state=18)\n",
    "    \n",
    "    # build NN model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_NN.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(), loss='mean_squared_error')\n",
    "    \n",
    "\n",
    "    # train NN\n",
    "    model.fit(X_train_NN, y_train_NN, epochs=epochs_, batch_size=32,\n",
    "              validation_data=(X_val_NN, y_val_NN))\n",
    "    \n",
    "    # evaluate model on test set    \n",
    "    predictions = model.predict(X_test_)\n",
    "    MSE_test = mean_squared_error(y_test_, predictions)\n",
    "    print(f'MSE Test: {round(MSE_test,4)}')\n",
    "\n",
    "    return model, predictions, MSE_test\n",
    "\n",
    "def set_seeds(seed=18):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9e89d-babc-47fb-a918-eaeb6896e614",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e0d8fe93-687a-41b2-9de3-4c3ffe1e2b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0638 - val_loss: 0.0579\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0536 - val_loss: 0.0584\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0587\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0574 - val_loss: 0.0490\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0452 - val_loss: 0.0484\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.049\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_tfidf, predictions_NN1_valence_tfidf, MSE_NN1_valence_tfidf = NN1(\n",
    "    X_train_ = X_train_tfidf, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_tfidf, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_tfidf, predictions_NN1_arousal_tfidf, MSE_NN1_arousal_tfidf = NN1(\n",
    "    X_train_ = X_train_tfidf, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_tfidf, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7700fcd-44c2-4756-8e45-87258ca1ee9d",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4cbbc848-3518-42d8-94f5-c4c9208f2bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0626 - val_loss: 0.0606\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0591\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0591\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 2ms/step - loss: 0.0552 - val_loss: 0.0484\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0493 - val_loss: 0.0497\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0488\n"
     ]
    }
   ],
   "source": [
    "# Pretrained, Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_Word2Vec_pretrained, predictions_NN1_valence_Word2Vec_pretrained, MSE_NN1_valence_Word2Vec_pretrained = NN1(\n",
    "    X_train_ = X_train_Word2Vec_pretrained, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Word2Vec_pretrained, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_Word2Vec_pretrained, predictions_NN1_arousal_Word2Vec_pretrained, MSE_NN1_arousal_Word2Vec_pretrained = NN1(\n",
    "    X_train_ = X_train_Word2Vec_pretrained, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Word2Vec_pretrained, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b9b1aee-33ad-44b0-bb5d-a628e9b58ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0642 - val_loss: 0.0623\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0592 - val_loss: 0.0603\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0624\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0576 - val_loss: 0.0522\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0519 - val_loss: 0.0517\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0547\n"
     ]
    }
   ],
   "source": [
    "# Pretrained, TF-IDF\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_Word2Vec_pretrained_tfidf, predictions_NN1_valence_Word2Vec_pretrained_tfidf, MSE_NN1_valence_Word2Vec_pretrained_tfidf = NN1(\n",
    "    X_train_Word2Vec_pretrained_tfidf, y_train_valence, X_test_Word2Vec_pretrained_tfidf, y_test_valence, \n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_Word2Vec_pretrained_tfidf, predictions_NN1_arousal_Word2Vec_pretrained_tfidf, MSE_NN1_arousal_Word2Vec_pretrained_tfidf = NN1(\n",
    "    X_train_Word2Vec_pretrained_tfidf, y_train_arousal, X_test_Word2Vec_pretrained_tfidf, y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fe19e83c-73f5-4faa-a6a4-6cb68d4a2b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 2ms/step - loss: 0.0618 - val_loss: 0.0601\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0574 - val_loss: 0.0577\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0579\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0533 - val_loss: 0.0479\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0482 - val_loss: 0.0471\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0468\n"
     ]
    }
   ],
   "source": [
    "# Custom, Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_Word2Vec_custom, predictions_NN1_valence_Word2Vec_custom, MSE_NN1_valence_Word2Vec_custom = NN1(\n",
    "    X_train_ = X_train_Word2Vec_custom, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Word2Vec_custom, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_Word2Vec_custom, predictions_NN1_arousal_Word2Vec_custom, MSE_NN1_arousal_Word2Vec_custom = NN1(\n",
    "    X_train_ = X_train_Word2Vec_custom, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Word2Vec_custom, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a060bbee-acfd-45bf-a83d-df4ce894082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0647 - val_loss: 0.0635\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0591 - val_loss: 0.0599\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.119\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0579 - val_loss: 0.0519\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0515 - val_loss: 0.0507\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.1488\n"
     ]
    }
   ],
   "source": [
    "# Custom, TF-IDF\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_Word2Vec_custom_tfidf, predictions_NN1_valence_Word2Vec_custom_tfidf, MSE_NN1_valence_Word2Vec_custom_tfidf = NN1(\n",
    "    X_train_ = X_train_Word2Vec_custom_tfidf, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Word2Vec_custom_tfidf, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_Word2Vec_custom_tfidf, predictions_NN1_arousal_Word2Vec_custom_tfidf, MSE_NN1_arousal_Word2Vec_custom_tfidf = NN1(\n",
    "    X_train_ = X_train_Word2Vec_custom_tfidf, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Word2Vec_custom_tfidf, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113b25d-7f51-4f21-b132-59385b0b2daf",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "92e3da59-abee-4e33-845b-5a5cc893ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 2ms/step - loss: 0.0637 - val_loss: 0.0573\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0569\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0587\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 2ms/step - loss: 0.0581 - val_loss: 0.0491\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0485 - val_loss: 0.0483\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0493\n"
     ]
    }
   ],
   "source": [
    "# Valence\n",
    "model_NN1_valence_Doc2Vec, predictions_NN1_valence_Doc2Vec, MSE_NN1_valence_Doc2Vec = NN1(\n",
    "    X_train_ = X_train_Doc2Vec, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Doc2Vec, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_Doc2Vec, predictions_NN1_arousal_Doc2Vec, MSE_NN1_arousal_Doc2Vec = NN1(\n",
    "    X_train_ = X_train_Doc2Vec, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Doc2Vec, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ef17e-4ba5-4ee2-960e-f8f2ee82972d",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dd07fc23-7486-4e33-91bd-3945e9e38bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 2ms/step - loss: 0.0619 - val_loss: 0.0605\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0570 - val_loss: 0.0585\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0587\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0541 - val_loss: 0.0481\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0477 - val_loss: 0.0471\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0464\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# Valence\n",
    "model_NN1_valence_GloVe_pretrained, predictions_NN1_valence_GloVe_pretrained, MSE_NN1_valence_GloVe_pretrained = NN1(\n",
    "    X_train_ = X_train_GloVe_pretrained, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_GloVe_pretrained, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_GloVe_pretrained, predictions_NN1_arousal_GloVe_pretrained, MSE_NN1_arousal_GloVe_pretrained = NN1(\n",
    "    X_train_ = X_train_GloVe_pretrained, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_GloVe_pretrained, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e4100658-9c72-4ab5-829d-1107cf198bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0637 - val_loss: 0.0599\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0582\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0588\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 2ms/step - loss: 0.0563 - val_loss: 0.0488\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0496 - val_loss: 0.0480\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0472\n"
     ]
    }
   ],
   "source": [
    "# Custom\n",
    "# Valence\n",
    "model_NN1_valence_GloVe_custom, predictions_NN1_valence_GloVe_custom, MSE_NN1_valence_GloVe_custom = NN1(\n",
    "    X_train_ = X_train_GloVe_custom, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_GloVe_custom, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_GloVe_custom, predictions_NN1_arousal_GloVe_custom, MSE_NN1_arousal_GloVe_custom = NN1(\n",
    "    X_train_ = X_train_GloVe_custom, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_GloVe_custom, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e806268b-14fe-466a-a2d8-0028dd76178c",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2eb95ba1-fa62-472d-9e36-f59f9bc64656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0639 - val_loss: 0.0582\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0594 - val_loss: 0.0587\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0594\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0555 - val_loss: 0.0484\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0504 - val_loss: 0.0505\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0497\n"
     ]
    }
   ],
   "source": [
    "# Pooler Outputs\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_BERT, predictions_NN1_valence_BERT, MSE_NN1_valence_BERT = NN1(\n",
    "    X_train_ = X_train_BERT, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_BERT, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_BERT, predictions_NN1_arousal_BERT, MSE_NN1_arousal_BERT = NN1(\n",
    "    X_train_ = X_train_BERT, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_BERT, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cc82c494-7dcd-4742-827a-9a2cac85d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0616 - val_loss: 0.0582\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0584 - val_loss: 0.0580\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0591\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0521 - val_loss: 0.0484\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0480 - val_loss: 0.0479\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0472\n"
     ]
    }
   ],
   "source": [
    "# CLS\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_BERT_CLS, predictions_NN1_valence_BERT_CLS, MSE_NN1_valence_BERT_CLS = NN1(\n",
    "    X_train_ = X_train_BERT_CLS, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_BERT_CLS, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_BERT_CLS, predictions_NN1_arousal_BERT_CLS, MSE_NN1_arousal_BERT_CLS = NN1(\n",
    "    X_train_ = X_train_BERT_CLS, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_BERT_CLS, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "59718161-d243-4702-a244-4f815750b126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0609 - val_loss: 0.0577\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0578 - val_loss: 0.0576\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0585\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 3s 3ms/step - loss: 0.0520 - val_loss: 0.0483\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0480 - val_loss: 0.0468\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0466\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_BERT_MeanPooling, predictions_NN1_valence_BERT_MeanPooling, MSE_NN1_valence_BERT_MeanPooling = NN1(\n",
    "    X_train_ = X_train_BERT_MeanPooling, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_BERT_MeanPooling, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_BERT_MeanPooling, predictions_NN1_arousal_BERT_MeanPooling, MSE_NN1_arousal_BERT_MeanPooling = NN1(\n",
    "    X_train_ = X_train_BERT_MeanPooling, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_BERT_MeanPooling, y_test_ = y_test_arousal,\n",
    "    epochs_=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a63d8-5b12-4779-be87-2eab6a9abca8",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a193db86-7346-4692-8d1a-328d68ccfef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0607 - val_loss: 0.0567\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0577 - val_loss: 0.0565\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0574\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0519 - val_loss: 0.0478\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0476 - val_loss: 0.0461\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0453\n"
     ]
    }
   ],
   "source": [
    "# CLS\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_DistillBERT_CLS, predictions_NN1_valence_DistillBERT_CLS, MSE_NN1_valence_DistillBERT_CLS = NN1(\n",
    "    X_train_ = X_train_DistillBERT_CLS, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_DistillBERT_CLS, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_DistillBERT_CLS, predictions_NN1_arousal_DistillBERT_CLS, MSE_NN1_arousal_DistillBERT_CLS = NN1(\n",
    "    X_train_ = X_train_DistillBERT_CLS, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_DistillBERT_CLS, y_test_ = y_test_arousal,\n",
    "    epochs_=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "49e4cf43-e188-4818-9cca-0ccc1fa2c116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0604 - val_loss: 0.0574\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0574 - val_loss: 0.0571\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0576\n",
      "---------------------------------------------------------\n",
      "Epoch 1/2\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0511 - val_loss: 0.0474\n",
      "Epoch 2/2\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0469 - val_loss: 0.0458\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0452\n"
     ]
    }
   ],
   "source": [
    "# Mean Pooling\n",
    "\n",
    "# Valence\n",
    "model_NN1_valence_DistillBERT_MeanPooling, predictions_NN1_valence_DistillBERT_MeanPooling, MSE_NN1_valence_DistillBERT_MeanPooling = NN1(\n",
    "    X_train_ = X_train_DistillBERT_MeanPooling, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_DistillBERT_MeanPooling, y_test_ = y_test_valence,\n",
    "    epochs_=2)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN1_arousal_DistillBERT_MeanPooling, predictions_NN1_arousal_DistillBERT_MeanPooling, MSE_NN1_arousal_DistillBERT_MeanPooling = NN1(\n",
    "    X_train_ = X_train_DistillBERT_MeanPooling, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_DistillBERT_MeanPooling, y_test_ = y_test_arousal,\n",
    "    epochs_=2)\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dde97f-fb54-45f8-b842-dcfd7849cb16",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f94139a4-b150-4696-a743-15a51f7d7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scipy.sparse import issparse\n",
    "import random\n",
    "\n",
    "def NN2(X_train_, y_train_, X_test_, y_test_, epochs_=2):\n",
    "    set_seeds(18)\n",
    "\n",
    "    if issparse(X_train_):\n",
    "        X_train_ = X_train_.toarray()\n",
    "    if issparse(X_test_):\n",
    "        X_test_ = X_test_.toarray()\n",
    "    \n",
    "    # holdout\n",
    "    X_train_NN, X_val_NN, y_train_NN, y_val_NN = train_test_split(X_train_, y_train_, test_size=0.2, random_state=18)\n",
    "\n",
    "    dropout_ = 0.25\n",
    "    # build NN model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_NN.shape[1],)))\n",
    "    model.add(Dropout(dropout_))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # linear output layer for regression\n",
    "\n",
    "    # compile \n",
    "    model.compile(optimizer= tf.compat.v1.train.AdamOptimizer(), loss='mean_squared_error')\n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # train NN\n",
    "    model.fit(X_train_NN, y_train_NN, epochs=epochs_, batch_size=32,\n",
    "              validation_data=(X_val_NN, y_val_NN))\n",
    "    \n",
    "    # evaluate model on test set    \n",
    "    predictions = model.predict(X_test_)\n",
    "    MSE_test = mean_squared_error(y_test_, predictions)\n",
    "    print(f'MSE Test: {round(MSE_test,4)}')\n",
    "\n",
    "    return model, predictions, MSE_test\n",
    "\n",
    "def set_seeds(seed=18):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2bd1abca-a95c-497b-b5c7-0583093fb9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Epoch 1/3\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0672 - val_loss: 0.0580\n",
      "Epoch 2/3\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0564 - val_loss: 0.0577\n",
      "Epoch 3/3\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0524 - val_loss: 0.0578\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.058\n",
      "---------------------------------------------------------\n",
      "Epoch 1/3\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0621 - val_loss: 0.0497\n",
      "Epoch 2/3\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0483 - val_loss: 0.0474\n",
      "Epoch 3/3\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0431 - val_loss: 0.0470\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0476\n",
      "Word2Vec, Pretrained, Mean Pooling\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0671 - val_loss: 0.0617\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0593 - val_loss: 0.0595\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0580 - val_loss: 0.0575\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0575 - val_loss: 0.0578\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0570 - val_loss: 0.0574\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0565 - val_loss: 0.0583\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0575\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0578\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0609 - val_loss: 0.0554\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0522 - val_loss: 0.0514\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0497 - val_loss: 0.0489\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0480\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0483 - val_loss: 0.0480\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0475 - val_loss: 0.0471\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0472 - val_loss: 0.0481\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0478\n",
      "Word2Vec, Custom, Mean Pooling\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0678 - val_loss: 0.0609\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0586 - val_loss: 0.0575\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0576 - val_loss: 0.0567\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0572 - val_loss: 0.0574\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0568 - val_loss: 0.0572\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0573\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0563\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0567\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0612 - val_loss: 0.0595\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0511 - val_loss: 0.0491\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0492 - val_loss: 0.0470\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0484 - val_loss: 0.0485\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0483 - val_loss: 0.0472\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0475 - val_loss: 0.0464\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0474 - val_loss: 0.0463\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0469\n",
      "Word2Vec, Custom, TF-IDF\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0724 - val_loss: 0.0618\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0605 - val_loss: 0.0591\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0594 - val_loss: 0.0585\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0589 - val_loss: 0.0593\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0588 - val_loss: 0.0588\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0585 - val_loss: 0.0591\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0582 - val_loss: 0.0579\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0649\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0678 - val_loss: 0.0578\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0540 - val_loss: 0.0543\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0526 - val_loss: 0.0504\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0515 - val_loss: 0.0517\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0513 - val_loss: 0.0503\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0496\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0504 - val_loss: 0.0499\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.065\n",
      "Doc2Vec\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0672 - val_loss: 0.0579\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0571\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0566 - val_loss: 0.0569\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0561 - val_loss: 0.0567\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0551 - val_loss: 0.0572\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0543 - val_loss: 0.0562\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0535 - val_loss: 0.0567\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0578\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0629 - val_loss: 0.0516\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0514 - val_loss: 0.0493\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0493 - val_loss: 0.0480\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0478 - val_loss: 0.0479\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0466 - val_loss: 0.0473\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0458 - val_loss: 0.0471\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0450 - val_loss: 0.0469\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0481\n",
      "Glove, Pretrained\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0683 - val_loss: 0.0604\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0588 - val_loss: 0.0575\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0572 - val_loss: 0.0568\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0567 - val_loss: 0.0570\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0566\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0552 - val_loss: 0.0570\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0548 - val_loss: 0.0563\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0569\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0625 - val_loss: 0.0527\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0509 - val_loss: 0.0484\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0475 - val_loss: 0.0473\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0468 - val_loss: 0.0471\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0462 - val_loss: 0.0466\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0457 - val_loss: 0.0473\n",
      "178/178 [==============================] - 2s 1ms/step\n",
      "MSE Test: 0.0468\n",
      "GloVe, Custom\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0677 - val_loss: 0.0589\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0595 - val_loss: 0.0577\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0583 - val_loss: 0.0582\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0581 - val_loss: 0.0583\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0578 - val_loss: 0.0580\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0576 - val_loss: 0.0583\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0573 - val_loss: 0.0575\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0578\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0613 - val_loss: 0.0494\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0516 - val_loss: 0.0483\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0502 - val_loss: 0.0488\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0498 - val_loss: 0.0486\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0494 - val_loss: 0.0479\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 1s 3ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0479\n",
      "BERT, Pooler Outputs\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0726 - val_loss: 0.0749\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0613 - val_loss: 0.0644\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0600 - val_loss: 0.0591\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0593 - val_loss: 0.0608\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0591 - val_loss: 0.0591\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0588 - val_loss: 0.0594\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0586 - val_loss: 0.0584\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0587\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0661 - val_loss: 0.0727\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0537 - val_loss: 0.0573\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0516 - val_loss: 0.0499\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0510 - val_loss: 0.0523\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0504 - val_loss: 0.0503\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0501 - val_loss: 0.0488\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0485\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0491\n",
      "BERT, CLS\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0715 - val_loss: 0.0669\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0598 - val_loss: 0.0636\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0585 - val_loss: 0.0579\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0583 - val_loss: 0.0579\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0578 - val_loss: 0.0576\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0575 - val_loss: 0.0582\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0572 - val_loss: 0.0577\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.058\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0639 - val_loss: 0.0703\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0517 - val_loss: 0.0533\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0498 - val_loss: 0.0477\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0489 - val_loss: 0.0489\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0484 - val_loss: 0.0470\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0477 - val_loss: 0.0474\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0478 - val_loss: 0.0468\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0474\n",
      "DistillBERT, Mean Pooling\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0697 - val_loss: 0.0684\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0595 - val_loss: 0.0604\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0584 - val_loss: 0.0575\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0582 - val_loss: 0.0580\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0577 - val_loss: 0.0582\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0575 - val_loss: 0.0581\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0571 - val_loss: 0.0579\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0581\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0616 - val_loss: 0.0651\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0512 - val_loss: 0.0540\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0493 - val_loss: 0.0472\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0483 - val_loss: 0.0482\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0481 - val_loss: 0.0466\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 1s 2ms/step - loss: 0.0473 - val_loss: 0.0459\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0473 - val_loss: 0.0462\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0467\n",
      "DistillBERT, CLS\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0674 - val_loss: 0.0672\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0587 - val_loss: 0.0602\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0577 - val_loss: 0.0567\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0575 - val_loss: 0.0591\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0572 - val_loss: 0.0580\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0569 - val_loss: 0.0582\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0570 - val_loss: 0.0567\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0574\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0596 - val_loss: 0.0594\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0492\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0484 - val_loss: 0.0470\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0476 - val_loss: 0.0474\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0473 - val_loss: 0.0462\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0469 - val_loss: 0.0462\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0471 - val_loss: 0.0455\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0453\n",
      "DistillBERT, Mean Pooling\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0662 - val_loss: 0.0661\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0583 - val_loss: 0.0618\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0576 - val_loss: 0.0571\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0573 - val_loss: 0.0571\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0569 - val_loss: 0.0567\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0566 - val_loss: 0.0573\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0563 - val_loss: 0.0560\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0565\n",
      "---------------------------------------------------------\n",
      "Epoch 1/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0581 - val_loss: 0.0617\n",
      "Epoch 2/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0496 - val_loss: 0.0523\n",
      "Epoch 3/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0478 - val_loss: 0.0472\n",
      "Epoch 4/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0470 - val_loss: 0.0469\n",
      "Epoch 5/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0465 - val_loss: 0.0458\n",
      "Epoch 6/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0462 - val_loss: 0.0457\n",
      "Epoch 7/7\n",
      "568/568 [==============================] - 2s 3ms/step - loss: 0.0461 - val_loss: 0.0460\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0458\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################################\n",
    "# TF-IDF\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('TF-IDF')\n",
    "# Valence\n",
    "model_NN2_valence_tfidf, predictions_NN2_valence_tfidf, MSE_NN2_valence_tfidf = NN2(\n",
    "    X_train_ = X_train_tfidf, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_tfidf, y_test_ = y_test_valence,\n",
    "    epochs_=3)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_tfidf, predictions_NN2_arousal_tfidf, MSE_NN2_arousal_tfidf = NN2(\n",
    "    X_train_ = X_train_tfidf, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_tfidf, y_test_ = y_test_arousal,\n",
    "    epochs_=3)\n",
    "\n",
    "##################################################################################################################\n",
    "eps = 7\n",
    "##################################################################################################################\n",
    "# Word2Vec, Pretrained, Mean Pooling\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('Word2Vec, Pretrained, Mean Pooling')\n",
    "# Valence\n",
    "model_NN2_valence_Word2Vec_pretrained, predictions_NN2_valence_Word2Vec_pretrained, MSE_NN2_valence_Word2Vec_pretrained = NN2(\n",
    "    X_train_ = X_train_Word2Vec_pretrained, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Word2Vec_pretrained, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_Word2Vec_pretrained, predictions_NN2_arousal_Word2Vec_pretrained, MSE_NN2_arousal_Word2Vec_pretrained = NN2(\n",
    "    X_train_ = X_train_Word2Vec_pretrained, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Word2Vec_pretrained, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# Word2Vec, Custom, Mean Pooling\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('Word2Vec, Custom, Mean Pooling')\n",
    "# Valence\n",
    "model_NN2_valence_Word2Vec_custom, predictions_NN2_valence_Word2Vec_custom, MSE_NN2_valence_Word2Vec_custom = NN2(\n",
    "    X_train_ = X_train_Word2Vec_custom, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Word2Vec_custom, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_Word2Vec_custom, predictions_NN2_arousal_Word2Vec_custom, MSE_NN2_arousal_Word2Vec_custom = NN2(\n",
    "    X_train_ = X_train_Word2Vec_custom, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Word2Vec_custom, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# Word2Vec, Custom, TF-IDF\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('Word2Vec, Custom, TF-IDF')\n",
    "# Valence\n",
    "model_NN2_valence_Word2Vec_custom_tfidf, predictions_NN2_valence_Word2Vec_custom_tfidf, MSE_NN2_valence_Word2Vec_custom_tfidf = NN2(\n",
    "    X_train_ = X_train_Word2Vec_custom_tfidf, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Word2Vec_custom_tfidf, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_Word2Vec_custom_tfidf, predictions_NN2_arousal_Word2Vec_custom_tfidf, MSE_NN2_arousal_Word2Vec_custom_tfidf = NN2(\n",
    "    X_train_ = X_train_Word2Vec_custom_tfidf, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Word2Vec_custom_tfidf, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "##################################################################################################################\n",
    "# Doc2Vec\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('Doc2Vec')\n",
    "# Valence\n",
    "model_NN2_valence_Doc2Vec, predictions_NN2_valence_Doc2Vec, MSE_NN2_valence_Doc2Vec = NN2(\n",
    "    X_train_ = X_train_Doc2Vec, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_Doc2Vec, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_Doc2Vec, predictions_NN2_arousal_Doc2Vec, MSE_NN2_arousal_Doc2Vec = NN2(\n",
    "    X_train_ = X_train_Doc2Vec, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_Doc2Vec, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# Glove, Pretrained\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('Glove, Pretrained')\n",
    "# Valence\n",
    "model_NN2_valence_GloVe_pretrained, predictions_NN2_valence_GloVe_pretrained, MSE_NN2_valence_GloVe_pretrained = NN2(\n",
    "    X_train_ = X_train_GloVe_pretrained, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_GloVe_pretrained, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_GloVe_pretrained, predictions_NN2_arousal_GloVe_pretrained, MSE_NN2_arousal_GloVe_pretrained = NN2(\n",
    "    X_train_ = X_train_GloVe_pretrained, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_GloVe_pretrained, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# GloVe, Custom\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('GloVe, Custom')\n",
    "# Valence\n",
    "model_NN2_valence_GloVe_custom, predictions_NN2_valence_GloVe_custom, MSE_NN2_valence_GloVe_custom = NN2(\n",
    "    X_train_ = X_train_GloVe_custom, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_GloVe_custom, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_GloVe_custom, predictions_NN2_arousal_GloVe_custom, MSE_NN2_arousal_GloVe_custom = NN2(\n",
    "    X_train_ = X_train_GloVe_custom, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_GloVe_custom, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# BERT, Pooler Outputs\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('BERT, Pooler Outputs')\n",
    "# Valence\n",
    "model_NN2_valence_BERT, predictions_NN2_valence_BERT, MSE_NN2_valence_BERT = NN2(\n",
    "    X_train_ = X_train_BERT, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_BERT, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_BERT, predictions_NN2_arousal_BERT, MSE_NN2_arousal_BERT = NN2(\n",
    "    X_train_ = X_train_BERT, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_BERT, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# BERT, CLS\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('BERT, CLS')\n",
    "# Valence\n",
    "model_NN2_valence_BERT_CLS, predictions_NN2_valence_BERT_CLS, MSE_NN2_valence_BERT_CLS = NN2(\n",
    "    X_train_ = X_train_BERT_CLS, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_BERT_CLS, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# BERT, Arousal\n",
    "model_NN2_arousal_BERT_CLS, predictions_NN2_arousal_BERT_CLS, MSE_NN2_arousal_BERT_CLS = NN2(\n",
    "    X_train_ = X_train_BERT_CLS, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_BERT_CLS, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# DistillBERT, Mean Pooling\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('DistillBERT, Mean Pooling')\n",
    "# Valence\n",
    "model_NN2_valence_BERT_MeanPooling, predictions_NN2_valence_BERT_MeanPooling, MSE_NN2_valence_BERT_MeanPooling = NN2(\n",
    "    X_train_ = X_train_BERT_MeanPooling, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_BERT_MeanPooling, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_BERT_MeanPooling, predictions_NN2_arousal_BERT_MeanPooling, MSE_NN2_arousal_BERT_MeanPooling = NN2(\n",
    "    X_train_ = X_train_BERT_MeanPooling, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_BERT_MeanPooling, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# DistillBERT, CLS\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('DistillBERT, CLS')\n",
    "# Valence\n",
    "model_NN2_valence_DistillBERT_CLS, predictions_NN2_valence_DistillBERT_CLS, MSE_NN2_valence_DistillBERT_CLS = NN2(\n",
    "    X_train_ = X_train_DistillBERT_CLS, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_DistillBERT_CLS, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_DistillBERT_CLS, predictions_NN2_arousal_DistillBERT_CLS, MSE_NN2_arousal_DistillBERT_CLS = NN2(\n",
    "    X_train_ = X_train_DistillBERT_CLS, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_DistillBERT_CLS, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\n",
    "\n",
    "##################################################################################################################\n",
    "# DistillBERT, Mean Pooling\n",
    "print('______________________________________________________________________')\n",
    "print('______________________________________________________________________')\n",
    "print('DistillBERT, Mean Pooling')\n",
    "# Valence\n",
    "model_NN2_valence_DistillBERT_MeanPooling, predictions_NN2_valence_DistillBERT_MeanPooling, MSE_NN2_valence_DistillBERT_MeanPooling = NN2(\n",
    "    X_train_ = X_train_DistillBERT_MeanPooling, y_train_ = y_train_valence, \n",
    "    X_test_ = X_test_DistillBERT_MeanPooling, y_test_ = y_test_valence,\n",
    "    epochs_=eps)\n",
    "print('---------------------------------------------------------')\n",
    "# Arousal\n",
    "model_NN2_arousal_DistillBERT_MeanPooling, predictions_NN2_arousal_DistillBERT_MeanPooling, MSE_NN2_arousal_DistillBERT_MeanPooling = NN2(\n",
    "    X_train_ = X_train_DistillBERT_MeanPooling, y_train_ = y_train_arousal, \n",
    "    X_test_ = X_test_DistillBERT_MeanPooling, y_test_ = y_test_arousal,\n",
    "    epochs_=eps)\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabefcf-67c9-4da1-9dd8-c42a09d64794",
   "metadata": {},
   "source": [
    "# MSE Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "222a0c14-82b0-4a2f-bef6-995aa202d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSE_tables():\n",
    "    mse_valence = {\n",
    "        'SGDR_valence': {\n",
    "            'tfidf': MSE_SGDR_valence_tfidf if 'MSE_SGDR_valence_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_SGDR_valence_Word2Vec_custom if 'MSE_SGDR_valence_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_SGDR_valence_Word2Vec_custom_tfidf if 'MSE_SGDR_valence_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_SGDR_valence_Word2Vec_pretrained if 'MSE_SGDR_valence_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_SGDR_valence_Word2Vec_pretrained_tfidf if 'MSE_SGDR_valence_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_SGDR_valence_Doc2Vec if 'MSE_SGDR_valence_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_SGDR_valence_GloVe_pretrained if 'MSE_SGDR_valence_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_SGDR_valence_GloVe_custom if 'MSE_SGDR_valence_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_SGDR_valence_BERT if 'MSE_SGDR_valence_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_SGDR_valence_BERT_CLS if 'MSE_SGDR_valence_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_SGDR_valence_BERT_MeanPooling if 'MSE_SGDR_valence_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_SGDR_valence_DistillBERT_CLS if 'MSE_SGDR_valence_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_SGDR_valence_DistillBERT_MeanPooling if 'MSE_SGDR_valence_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        },\n",
    "        'GBT_valence': {\n",
    "            'tfidf': MSE_GBT_valence_tfidf if 'MSE_GBT_valence_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_GBT_valence_Word2Vec_custom if 'MSE_GBT_valence_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_GBT_valence_Word2Vec_custom_tfidf if 'MSE_GBT_valence_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_GBT_valence_Word2Vec_pretrained if 'MSE_GBT_valence_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_GBT_valence_Word2Vec_pretrained_tfidf if 'MSE_GBT_valence_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_GBT_valence_Doc2Vec if 'MSE_GBT_valence_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_GBT_valence_GloVe_pretrained if 'MSE_GBT_valence_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_GBT_valence_GloVe_custom if 'MSE_GBT_valence_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_GBT_valence_BERT if 'MSE_GBT_valence_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_GBT_valence_BERT_CLS if 'MSE_GBT_valence_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_GBT_valence_BERT_MeanPooling if 'MSE_GBT_valence_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_GBT_valence_DistillBERT_CLS if 'MSE_GBT_valence_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_GBT_valence_DistillBERT_MeanPooling if 'MSE_GBT_valence_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        },\n",
    "        'NN1_valence': {\n",
    "            'tfidf': MSE_NN1_valence_tfidf if 'MSE_NN1_valence_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_NN1_valence_Word2Vec_custom if 'MSE_NN1_valence_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_NN1_valence_Word2Vec_custom_tfidf if 'MSE_NN1_valence_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_NN1_valence_Word2Vec_pretrained if 'MSE_NN1_valence_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_NN1_valence_Word2Vec_pretrained_tfidf if 'MSE_NN1_valence_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_NN1_valence_Doc2Vec if 'MSE_NN1_valence_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_NN1_valence_GloVe_pretrained if 'MSE_NN1_valence_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_NN1_valence_GloVe_custom if 'MSE_NN1_valence_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_NN1_valence_BERT if 'MSE_NN1_valence_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_NN1_valence_BERT_CLS if 'MSE_NN1_valence_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_NN1_valence_BERT_MeanPooling if 'MSE_NN1_valence_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_NN1_valence_DistillBERT_CLS if 'MSE_NN1_valence_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_NN1_valence_DistillBERT_MeanPooling if 'MSE_NN1_valence_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        },\n",
    "        'NN2_valence': {\n",
    "            'tfidf': MSE_NN2_valence_tfidf if 'MSE_NN2_valence_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_NN2_valence_Word2Vec_custom if 'MSE_NN2_valence_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_NN2_valence_Word2Vec_custom_tfidf if 'MSE_NN2_valence_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_NN2_valence_Word2Vec_pretrained if 'MSE_NN2_valence_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_NN2_valence_Word2Vec_pretrained_tfidf if 'MSE_NN2_valence_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_NN2_valence_Doc2Vec if 'MSE_NN2_valence_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_NN2_valence_GloVe_pretrained if 'MSE_NN2_valence_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_NN2_valence_GloVe_custom if 'MSE_NN2_valence_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_NN2_valence_BERT if 'MSE_NN2_valence_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_NN2_valence_BERT_CLS if 'MSE_NN2_valence_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_NN2_valence_BERT_MeanPooling if 'MSE_NN2_valence_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_NN2_valence_DistillBERT_CLS if 'MSE_NN2_valence_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_NN2_valence_DistillBERT_MeanPooling if 'MSE_NN2_valence_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    mse_arousal = {\n",
    "        'SGDR_arousal': {\n",
    "            'tfidf': MSE_SGDR_arousal_tfidf if 'MSE_SGDR_arousal_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_SGDR_arousal_Word2Vec_custom if 'MSE_SGDR_arousal_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_SGDR_arousal_Word2Vec_custom_tfidf if 'MSE_SGDR_arousal_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_SGDR_arousal_Word2Vec_pretrained if 'MSE_SGDR_arousal_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_SGDR_arousal_Word2Vec_pretrained_tfidf if 'MSE_SGDR_arousal_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_SGDR_arousal_Doc2Vec if 'MSE_SGDR_arousal_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_SGDR_arousal_GloVe_pretrained if 'MSE_SGDR_arousal_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_SGDR_arousal_GloVe_custom if 'MSE_SGDR_arousal_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_SGDR_arousal_BERT if 'MSE_SGDR_arousal_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_SGDR_arousal_BERT_CLS if 'MSE_SGDR_arousal_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_SGDR_arousal_BERT_MeanPooling if 'MSE_SGDR_arousal_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_SGDR_arousal_DistillBERT_CLS if 'MSE_SGDR_arousal_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_SGDR_arousal_DistillBERT_MeanPooling if 'MSE_SGDR_arousal_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        },\n",
    "        'GBT_arousal': {\n",
    "            'tfidf': MSE_GBT_arousal_tfidf if 'MSE_GBT_arousal_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_GBT_arousal_Word2Vec_custom if 'MSE_GBT_arousal_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_GBT_arousal_Word2Vec_custom_tfidf if 'MSE_GBT_arousal_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_GBT_arousal_Word2Vec_pretrained if 'MSE_GBT_arousal_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_GBT_arousal_Word2Vec_pretrained_tfidf if 'MSE_GBT_arousal_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_GBT_arousal_Doc2Vec if 'MSE_GBT_arousal_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_GBT_arousal_GloVe_pretrained if 'MSE_GBT_arousal_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_GBT_arousal_GloVe_custom if 'MSE_GBT_arousal_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_GBT_arousal_BERT if 'MSE_GBT_arousal_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_GBT_arousal_BERT_CLS if 'MSE_GBT_arousal_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_GBT_arousal_BERT_MeanPooling if 'MSE_GBT_arousal_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_GBT_arousal_DistillBERT_CLS if 'MSE_GBT_arousal_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_GBT_arousal_DistillBERT_MeanPooling if 'MSE_GBT_arousal_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        },\n",
    "        'NN1_arousal': {\n",
    "            'tfidf': MSE_NN1_arousal_tfidf if 'MSE_NN1_arousal_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_NN1_arousal_Word2Vec_custom if 'MSE_NN1_arousal_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_NN1_arousal_Word2Vec_custom_tfidf if 'MSE_NN1_arousal_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_NN1_arousal_Word2Vec_pretrained if 'MSE_NN1_arousal_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_NN1_arousal_Word2Vec_pretrained_tfidf if 'MSE_NN1_arousal_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_NN1_arousal_Doc2Vec if 'MSE_NN1_arousal_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_NN1_arousal_GloVe_pretrained if 'MSE_NN1_arousal_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_NN1_arousal_GloVe_custom if 'MSE_NN1_arousal_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_NN1_arousal_BERT if 'MSE_NN1_arousal_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_NN1_arousal_BERT_CLS if 'MSE_NN1_arousal_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_NN1_arousal_BERT_MeanPooling if 'MSE_NN1_arousal_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_NN1_arousal_DistillBERT_CLS if 'MSE_NN1_arousal_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_NN1_arousal_DistillBERT_MeanPooling if 'MSE_NN1_arousal_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        },\n",
    "        'NN2_arousal': {\n",
    "            'tfidf': MSE_NN2_arousal_tfidf if 'MSE_NN2_arousal_tfidf' in globals() else '-',\n",
    "            'Word2Vec_custom': MSE_NN2_arousal_Word2Vec_custom if 'MSE_NN2_arousal_Word2Vec_custom' in globals() else '-',\n",
    "            'Word2Vec_custom_tfidf': MSE_NN2_arousal_Word2Vec_custom_tfidf if 'MSE_NN2_arousal_Word2Vec_custom_tfidf' in globals() else '-',\n",
    "            'Word2Vec_pretrained': MSE_NN2_arousal_Word2Vec_pretrained if 'MSE_NN2_arousal_Word2Vec_pretrained' in globals() else '-',\n",
    "            'Word2Vec_pretrained_tfidf': MSE_NN2_arousal_Word2Vec_pretrained_tfidf if 'MSE_NN2_arousal_Word2Vec_pretrained_tfidf' in globals() else '-',\n",
    "            'Doc2Vec': MSE_NN2_arousal_Doc2Vec if 'MSE_NN2_arousal_Doc2Vec' in globals() else '-',\n",
    "            'GloVe_pretrained': MSE_NN2_arousal_GloVe_pretrained if 'MSE_NN2_arousal_GloVe_pretrained' in globals() else '-',\n",
    "            'GloVe_custom': MSE_NN2_arousal_GloVe_custom if 'MSE_NN2_arousal_GloVe_custom' in globals() else '-',\n",
    "            'BERT': MSE_NN2_arousal_BERT if 'MSE_NN2_arousal_BERT' in globals() else '-',\n",
    "            'BERT_CLS': MSE_NN2_arousal_BERT_CLS if 'MSE_NN2_arousal_BERT_CLS' in globals() else '-',\n",
    "            'BERT_MeanPooling': MSE_NN2_arousal_BERT_MeanPooling if 'MSE_NN2_arousal_BERT_MeanPooling' in globals() else '-',\n",
    "            'DistillBERT_CLS': MSE_NN2_arousal_DistillBERT_CLS if 'MSE_NN2_arousal_DistillBERT_CLS' in globals() else '-',\n",
    "            'DistillBERT_MeanPooling': MSE_NN2_arousal_DistillBERT_MeanPooling if 'MSE_NN2_arousal_DistillBERT_MeanPooling' in globals() else '-'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    mse_valence_table = pd.DataFrame(mse_valence).T\n",
    "    mse_valence_table.columns = ['tfidf', 'Word2Vec_custom', 'Word2Vec_custom_tfidf', 'Word2Vec_pretrained', 'Word2Vec_pretrained_tfidf',\n",
    "                                 'Doc2Vec', 'GloVe_pretrained', 'GloVe_custom', 'BERT', 'BERT_CLS', 'BERT_MeanPooling', 'DistillBERT_CLS', 'DistillBERT_MeanPooling']\n",
    "     \n",
    "    mse_arousal_table = pd.DataFrame(mse_arousal).T\n",
    "    mse_arousal_table.columns = ['tfidf', 'Word2Vec_custom', 'Word2Vec_custom_tfidf', 'Word2Vec_pretrained', 'Word2Vec_pretrained_tfidf',\n",
    "                                 'Doc2Vec', 'GloVe_pretrained', 'GloVe_custom', 'BERT', 'BERT_CLS', 'BERT_MeanPooling', 'DistillBERT_CLS', 'DistillBERT_MeanPooling']\n",
    "    \n",
    "    mse_valence_table = mse_valence_table.T\n",
    "    mse_arousal_table = mse_arousal_table.T\n",
    "    \n",
    "    return mse_valence_table, mse_arousal_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd9b14-d269-41a3-a9bd-ebd5fceb1ddf",
   "metadata": {},
   "source": [
    "## View tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "be0697ce-8950-4cdf-a7d6-ed474a20d0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SGDR_valence</th>\n",
       "      <th>GBT_valence</th>\n",
       "      <th>NN1_valence</th>\n",
       "      <th>NN2_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.058777</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>0.066454</td>\n",
       "      <td>0.057967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_custom</th>\n",
       "      <td>0.057487</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>0.056744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_custom_tfidf</th>\n",
       "      <td>0.068163</td>\n",
       "      <td>0.065986</td>\n",
       "      <td>0.118952</td>\n",
       "      <td>0.064858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_pretrained</th>\n",
       "      <td>0.057713</td>\n",
       "      <td>0.058089</td>\n",
       "      <td>0.059115</td>\n",
       "      <td>0.057762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_pretrained_tfidf</th>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.061447</td>\n",
       "      <td>0.062382</td>\n",
       "      <td>0.062739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec</th>\n",
       "      <td>0.059704</td>\n",
       "      <td>0.058096</td>\n",
       "      <td>0.058657</td>\n",
       "      <td>0.057792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_pretrained</th>\n",
       "      <td>0.057403</td>\n",
       "      <td>0.057324</td>\n",
       "      <td>0.058650</td>\n",
       "      <td>0.056917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_custom</th>\n",
       "      <td>0.057989</td>\n",
       "      <td>0.057711</td>\n",
       "      <td>0.058779</td>\n",
       "      <td>0.057815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT</th>\n",
       "      <td>0.057976</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.058715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT_CLS</th>\n",
       "      <td>0.057678</td>\n",
       "      <td>0.057984</td>\n",
       "      <td>0.059127</td>\n",
       "      <td>0.057996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT_MeanPooling</th>\n",
       "      <td>0.057393</td>\n",
       "      <td>0.057720</td>\n",
       "      <td>0.058548</td>\n",
       "      <td>0.058135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistillBERT_CLS</th>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.057199</td>\n",
       "      <td>0.057365</td>\n",
       "      <td>0.057433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistillBERT_MeanPooling</th>\n",
       "      <td>0.056417</td>\n",
       "      <td>0.057428</td>\n",
       "      <td>0.057595</td>\n",
       "      <td>0.056494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SGDR_valence  GBT_valence  NN1_valence  NN2_valence\n",
       "tfidf                          0.058777     0.057301     0.066454     0.057967\n",
       "Word2Vec_custom                0.057487     0.056657     0.057884     0.056744\n",
       "Word2Vec_custom_tfidf          0.068163     0.065986     0.118952     0.064858\n",
       "Word2Vec_pretrained            0.057713     0.058089     0.059115     0.057762\n",
       "Word2Vec_pretrained_tfidf      0.061078     0.061447     0.062382     0.062739\n",
       "Doc2Vec                        0.059704     0.058096     0.058657     0.057792\n",
       "GloVe_pretrained               0.057403     0.057324     0.058650     0.056917\n",
       "GloVe_custom                   0.057989     0.057711     0.058779     0.057815\n",
       "BERT                           0.057976     0.058791     0.059401     0.058715\n",
       "BERT_CLS                       0.057678     0.057984     0.059127     0.057996\n",
       "BERT_MeanPooling               0.057393     0.057720     0.058548     0.058135\n",
       "DistillBERT_CLS                0.056844     0.057199     0.057365     0.057433\n",
       "DistillBERT_MeanPooling        0.056417     0.057428     0.057595     0.056494"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_mse_valence, table_mse_arousal = get_MSE_tables()\n",
    "table_mse_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "875385d7-3b88-44b6-b2f0-e6329644504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SGDR_arousal</th>\n",
       "      <th>GBT_arousal</th>\n",
       "      <th>NN1_arousal</th>\n",
       "      <th>NN2_arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.048874</td>\n",
       "      <td>0.046470</td>\n",
       "      <td>0.053964</td>\n",
       "      <td>0.047641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_custom</th>\n",
       "      <td>0.047951</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.046764</td>\n",
       "      <td>0.046942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_custom_tfidf</th>\n",
       "      <td>0.090276</td>\n",
       "      <td>0.061776</td>\n",
       "      <td>0.148779</td>\n",
       "      <td>0.064953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_pretrained</th>\n",
       "      <td>0.048106</td>\n",
       "      <td>0.048770</td>\n",
       "      <td>0.048803</td>\n",
       "      <td>0.047756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec_pretrained_tfidf</th>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.055555</td>\n",
       "      <td>0.054738</td>\n",
       "      <td>0.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec</th>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.048979</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.048125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_pretrained</th>\n",
       "      <td>0.047566</td>\n",
       "      <td>0.046898</td>\n",
       "      <td>0.046382</td>\n",
       "      <td>0.046820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_custom</th>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.047622</td>\n",
       "      <td>0.047231</td>\n",
       "      <td>0.047929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT</th>\n",
       "      <td>0.047290</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>0.049679</td>\n",
       "      <td>0.049103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT_CLS</th>\n",
       "      <td>0.045954</td>\n",
       "      <td>0.046612</td>\n",
       "      <td>0.047207</td>\n",
       "      <td>0.047357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT_MeanPooling</th>\n",
       "      <td>0.046310</td>\n",
       "      <td>0.046118</td>\n",
       "      <td>0.046586</td>\n",
       "      <td>0.046727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistillBERT_CLS</th>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.045394</td>\n",
       "      <td>0.045306</td>\n",
       "      <td>0.045303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistillBERT_MeanPooling</th>\n",
       "      <td>0.044993</td>\n",
       "      <td>0.045666</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>0.045827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SGDR_arousal  GBT_arousal  NN1_arousal  NN2_arousal\n",
       "tfidf                          0.048874     0.046470     0.053964     0.047641\n",
       "Word2Vec_custom                0.047951     0.046115     0.046764     0.046942\n",
       "Word2Vec_custom_tfidf          0.090276     0.061776     0.148779     0.064953\n",
       "Word2Vec_pretrained            0.048106     0.048770     0.048803     0.047756\n",
       "Word2Vec_pretrained_tfidf      0.054306     0.055555     0.054738     0.052900\n",
       "Doc2Vec                        0.053370     0.048979     0.049275     0.048125\n",
       "GloVe_pretrained               0.047566     0.046898     0.046382     0.046820\n",
       "GloVe_custom                   0.049256     0.047622     0.047231     0.047929\n",
       "BERT                           0.047290     0.047997     0.049679     0.049103\n",
       "BERT_CLS                       0.045954     0.046612     0.047207     0.047357\n",
       "BERT_MeanPooling               0.046310     0.046118     0.046586     0.046727\n",
       "DistillBERT_CLS                0.044772     0.045394     0.045306     0.045303\n",
       "DistillBERT_MeanPooling        0.044993     0.045666     0.045227     0.045827"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_mse_arousal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3glVOwJv89e0"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "buWoSjjE8Nqy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "np.int = int\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cross_val = KFold(n_splits=5, shuffle = True, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "os.chdir('G:/Meine Ablage/Studium/03 UC3M/Thesis/Data')\n",
    "subfolder = 'Data Augmentation nlpaug'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcd2eUltdXBB"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18196,
     "status": "ok",
     "timestamp": 1722591854768,
     "user": {
      "displayName": "Moritz Roller",
      "userId": "06905633796207639823"
     },
     "user_tz": -120
    },
    "id": "6CTVns57dYzZ",
    "outputId": "a428ece0-af79-4658-f535-2711497f4cd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5675,)\n",
      "(5675,)\n",
      "(108945,)\n",
      "(108945,)\n",
      "TF-IDF augmented: (108945, 635) &  (5675, 635)\n",
      "Word2Vec pretrained augmented: (108945, 300) &  (5675, 300)\n",
      "GloVe pretrained augmented: (108945, 300) &  (5675, 300)\n",
      "BERT pretrained augmented: (108945, 768) &  (5675, 768)\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# y_test (not augmented!!)\n",
    "\n",
    "y_test_valence = np.load('y_test_valence.npy')\n",
    "y_test_arousal = np.load('y_test_arousal.npy')\n",
    "print(y_test_valence.shape)\n",
    "print(y_test_arousal.shape)\n",
    "\n",
    "##################################################################################\n",
    "# y_train\n",
    "y_train_valence_augmented = np.load(os.path.join(subfolder, 'y_train_valence_augmented.npy'))\n",
    "y_train_arousal_augmented = np.load(os.path.join(subfolder, 'y_train_arousal_augmented.npy'))\n",
    "print(y_train_valence_augmented.shape)\n",
    "print(y_train_arousal_augmented.shape)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# TF-IDF\n",
    "X_train_tfidf_augmented = sparse.load_npz(os.path.join(subfolder, 'X_train_tfidf_augmented.npz')).toarray()\n",
    "X_test_tfidf = sparse.load_npz(os.path.join(subfolder, 'X_test_tfidf.npz')).toarray()\n",
    "print(\"TF-IDF augmented:\", X_train_tfidf_augmented.shape, \"& \", X_test_tfidf.shape)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# Word2Vec pretrained\n",
    "X_train_Word2Vec_pretrained_augmented = np.load(os.path.join(subfolder, 'X_train_Word2Vec_pretrained_augmented.npy'))\n",
    "X_test_Word2Vec_pretrained = np.load(os.path.join('Word2Vec', 'X_test_Word2Vec_pretrained.npy'))\n",
    "print(\"Word2Vec pretrained augmented:\", X_train_Word2Vec_pretrained_augmented.shape, \"& \", X_test_Word2Vec_pretrained.shape)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# GloVE pretrained\n",
    "X_train_GloVe_pretrained_augmented = np.load(os.path.join(subfolder, 'X_train_GloVe_pretrained_augmented.npy'))\n",
    "X_test_GloVe_pretrained = np.load(os.path.join('GloVe', 'X_test_GloVe_pretrained.npy'))\n",
    "print(\"GloVe pretrained augmented:\", X_train_GloVe_pretrained_augmented.shape,  \"& \", X_test_GloVe_pretrained.shape)\n",
    "\n",
    "##################################################################################\n",
    "# BERT\n",
    "X_train_BERT_augmented = np.load(os.path.join(subfolder, 'X_train_BERT_augmented.npy'))\n",
    "X_test_BERT = torch.load(os.path.join('BERT', 'BERT_test_pooler_outputs.pt')).numpy()\n",
    "print(\"BERT pretrained augmented:\", X_train_BERT_augmented.shape, \"& \", X_test_BERT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import warnings\n",
    "\n",
    "def SGDR_Regressor(X_train_, y_train_, X_test_, y_test_, param_grid_):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    param_grid = param_grid_\n",
    "    \n",
    "    warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n",
    "    SGDR_opt = BayesSearchCV(\n",
    "      SGDRegressor(random_state=18),\n",
    "      search_spaces=param_grid_, n_iter=50, cv=cross_val, scoring='neg_mean_squared_error', n_jobs=4, verbose=False, random_state=18)\n",
    "    SGDR_opt.fit(X_train_, y_train_)\n",
    "    \n",
    "    t1 = time.time()-t0\n",
    "    print(f'Duration: {round(t1,2)} s')\n",
    "\n",
    "    print(f'{SGDR_opt.best_params_=}')\n",
    "    print(f'{SGDR_opt.best_score_=}')\n",
    "\n",
    "    # predict test\n",
    "    predictions = SGDR_opt.best_estimator_.predict(X_test_)\n",
    "    MSE_test = mean_squared_error(y_test_, predictions)\n",
    "    print(f'MSE Test: {round(MSE_test,4)}')\n",
    "    \n",
    "    return SGDR_opt, predictions, MSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_iter': Integer(1000,10000),\n",
    "    'tol': [1e-6],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': Real(1e-5, 1e0), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 725.23 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 8436), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05562443534995691\n",
      "MSE Test: 0.0578\n",
      "---------------------------------------------------------\n",
      "Duration: 737.09 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 8436), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04730765979995083\n",
      "MSE Test: 0.0482\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# TF-IDF\n",
    "##################################################################################\n",
    "\n",
    "# Valence\n",
    "model_SGDR_valence_tfidf_augmented, predictions_SGDR_valence_tfidf_augmented, MSE_SGDR_valence_tfidf_augmented = SGDR_Regressor(\n",
    "    X_train_tfidf_augmented, y_train_valence_augmented, X_test_tfidf, y_test_valence, param_grid)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_SGDR_arousal_tfidf_augmented, predictions_SGDR_arousal_tfidf_augmented, MSE_SGDR_arousal_tfidf_augmented = SGDR_Regressor(\n",
    "    X_train_tfidf_augmented, y_train_arousal_augmented, X_test_tfidf, y_test_arousal, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 506.87 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 8437), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.056751446851602494\n",
      "MSE Test: 0.0578\n",
      "---------------------------------------------------------\n",
      "Duration: 620.8 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 8436), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.048492466346989754\n",
      "MSE Test: 0.0481\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# Word2Vec pretrained\n",
    "##################################################################################\n",
    "\n",
    "# valence\n",
    "model_SGDR_valence_Word2Vec_pretrained_augmented, predictions_SGDR_valence_Word2Vec_pretrained_augmented, MSE_SGDR_valence_Word2Vec_pretrained_augmented = SGDR_Regressor(\n",
    "    X_train_Word2Vec_pretrained_augmented, y_train_valence_augmented, X_test_Word2Vec_pretrained, y_test_valence, param_grid)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_SGDR_arousal_Word2Vec_pretrained_augmented, predictions_SGDR_arousal_Word2Vec_pretrained_augmented, MSE_SGDR_arousal_Word2Vec_pretrained_augmented = SGDR_Regressor(\n",
    "    X_train_Word2Vec_pretrained_augmented, y_train_arousal_augmented, X_test_Word2Vec_pretrained, y_test_arousal, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 466.21 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 8435), ('penalty', 'l2'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05636248443668407\n",
      "MSE Test: 0.0577\n",
      "---------------------------------------------------------\n",
      "Duration: 447.84 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 10000), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04787488795489142\n",
      "MSE Test: 0.0478\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# GloVe pretrained\n",
    "##################################################################################\n",
    "\n",
    "# valence\n",
    "model_SGDR_valence_GloVe_pretrained_augmented, predictions_SGDR_valence_GloVe_pretrained_augmented, MSE_SGDR_valence_GloVe_pretrained_augmented = SGDR_Regressor(\n",
    "    X_train_GloVe_pretrained_augmented, y_train_valence_augmented, X_test_GloVe_pretrained, y_test_valence, param_grid)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_SGDR_arousal_GloVe_pretrained_augmented, predictions_SGDR_arousal_GloVe_pretrained_augmented, MSE_SGDR_arousal_GloVe_pretrained_augmented = SGDR_Regressor(\n",
    "    X_train_GloVe_pretrained_augmented, y_train_arousal_augmented, X_test_GloVe_pretrained, y_test_arousal, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1504.45 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 0.00012358063208553572), ('max_iter', 8811), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.05610375195049999\n",
      "MSE Test: 0.0579\n",
      "---------------------------------------------------------\n",
      "Duration: 1586.14 s\n",
      "SGDR_opt.best_params_=OrderedDict([('alpha', 1e-05), ('max_iter', 1000), ('penalty', 'elasticnet'), ('tol', 1e-06)])\n",
      "SGDR_opt.best_score_=-0.04684045299839301\n",
      "MSE Test: 0.0459\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# BERT\n",
    "##################################################################################\n",
    "\n",
    "# valence\n",
    "model_SGDR_valence_BERT_augmented, predictions_SGDR_valence_BERT_augmented, MSE_SGDR_valence_BERT_augmented = SGDR_Regressor(\n",
    "    X_train_BERT_augmented, y_train_valence_augmented, X_test_BERT, y_test_valence, param_grid)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_SGDR_arousal_BERT_augmented, predictions_SGDR_arousal_BERT_augmented, MSE_SGDR_arousal_BERT_augmented = SGDR_Regressor(\n",
    "    X_train_BERT_augmented, y_train_arousal_augmented, X_test_BERT, y_test_arousal, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scipy.sparse import issparse\n",
    "import random\n",
    "\n",
    "def NN2(X_train_, y_train_, X_test_, y_test_, epochs_=2):\n",
    "    set_seeds(18)\n",
    "\n",
    "    if issparse(X_train_):\n",
    "        X_train_ = X_train_.toarray()\n",
    "    if issparse(X_test_):\n",
    "        X_test_ = X_test_.toarray()\n",
    "    \n",
    "    # holdout\n",
    "    X_train_NN, X_val_NN, y_train_NN, y_val_NN = train_test_split(X_train_, y_train_, test_size=0.2, random_state=18)\n",
    "\n",
    "    dropout_ = 0.25\n",
    "    # build NN model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_NN.shape[1],)))\n",
    "    model.add(Dropout(dropout_))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "\n",
    "    # compile \n",
    "    model.compile(optimizer= tf.compat.v1.train.AdamOptimizer(), loss='mean_squared_error')\n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # train NN\n",
    "    model.fit(X_train_NN, y_train_NN, epochs=epochs_, batch_size=32,\n",
    "              validation_data=(X_val_NN, y_val_NN))\n",
    "    \n",
    "    # evaluate model on test set    \n",
    "    predictions = model.predict(X_test_)\n",
    "    MSE_test = mean_squared_error(y_test_, predictions)\n",
    "    print(f'MSE Test: {round(MSE_test,4)}')\n",
    "\n",
    "    return model, predictions, MSE_test\n",
    "\n",
    "def set_seeds(seed=18):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0549 - val_loss: 0.0417\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0342 - val_loss: 0.0257\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0243 - val_loss: 0.0206\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0203 - val_loss: 0.0174\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0180 - val_loss: 0.0156\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0145 - val_loss: 0.0139\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "MSE Test: 0.0723\n",
      "---------------------------------------------------------\n",
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0473 - val_loss: 0.0337\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0287 - val_loss: 0.0217\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0204 - val_loss: 0.0172\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0170 - val_loss: 0.0150\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0083 - val_loss: 0.0098\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "MSE Test: 0.0557\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# TF-IDF\n",
    "##################################################################################\n",
    "\n",
    "# Valence\n",
    "model_NN2_valence_tfidf_augmented, predictions_NN2_valence_tfidf_augmented, MSE_NN2_valence_tfidf_augmented = NN2(\n",
    "    X_train_tfidf_augmented, y_train_valence_augmented, X_test_tfidf, y_test_valence,\n",
    "    epochs_=20)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_NN2_arousal_tfidf_augmented, predictions_NN2_arousal_tfidf_augmented, MSE_NN2_arousal_tfidf_augmented = NN2(\n",
    "    X_train_tfidf_augmented, y_train_arousal_augmented, X_test_tfidf, y_test_arousal,\n",
    "    epochs_=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0601 - val_loss: 0.0559\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0566 - val_loss: 0.0546\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0551 - val_loss: 0.0530\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0533 - val_loss: 0.0517\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0515 - val_loss: 0.0501\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0497 - val_loss: 0.0479\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0481 - val_loss: 0.0468\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0468 - val_loss: 0.0467\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0454 - val_loss: 0.0453\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0441 - val_loss: 0.0445\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0429 - val_loss: 0.0422\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0419 - val_loss: 0.0421\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0407 - val_loss: 0.0410\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0399 - val_loss: 0.0399\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0392 - val_loss: 0.0393\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0388 - val_loss: 0.0398\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0378 - val_loss: 0.0380\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0371 - val_loss: 0.0374\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0368 - val_loss: 0.0361\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0362 - val_loss: 0.0364\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "MSE Test: 0.0625\n",
      "---------------------------------------------------------\n",
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0524 - val_loss: 0.0475\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0477 - val_loss: 0.0464\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0460 - val_loss: 0.0437\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0442 - val_loss: 0.0422\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0425 - val_loss: 0.0407\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0409 - val_loss: 0.0422\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0393 - val_loss: 0.0386\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0379 - val_loss: 0.0379\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0370 - val_loss: 0.0365\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0358 - val_loss: 0.0364\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0351 - val_loss: 0.0353\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0340 - val_loss: 0.0335\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0333 - val_loss: 0.0330\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0326 - val_loss: 0.0325\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0321 - val_loss: 0.0331\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0312 - val_loss: 0.0322\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0308 - val_loss: 0.0309\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0298 - val_loss: 0.0299\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0294 - val_loss: 0.0288\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "MSE Test: 0.0529\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# Word2Vec, Pretrained\n",
    "##################################################################################\n",
    "\n",
    "# Valence\n",
    "model_NN2_valence_Word2Vec_pretrained_augmented, predictions_NN2_valence_Word2Vec_pretrained_augmented, MSE_NN2_valence_Word2Vec_pretrained_augmented = NN2(\n",
    "    X_train_Word2Vec_pretrained_augmented, y_train_valence_augmented, X_test_Word2Vec_pretrained, y_test_valence,\n",
    "    epochs_=20)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_NN2_arousal_Word2Vec_pretrained_augmented, predictions_NN2_arousal_Word2Vec_pretrained_augmented, MSE_NN2_arousal_Word2Vec_pretrained_augmented = NN2(\n",
    "    X_train_Word2Vec_pretrained_augmented, y_train_arousal_augmented, X_test_Word2Vec_pretrained, y_test_arousal,\n",
    "    epochs_=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0600 - val_loss: 0.0553\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0556 - val_loss: 0.0534\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0536 - val_loss: 0.0519\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0514 - val_loss: 0.0495\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0490 - val_loss: 0.0476\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0472 - val_loss: 0.0456\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0456 - val_loss: 0.0451\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0441 - val_loss: 0.0448\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0429 - val_loss: 0.0431\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0419 - val_loss: 0.0412\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0406 - val_loss: 0.0405\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0396 - val_loss: 0.0398\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0388 - val_loss: 0.0388\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0380 - val_loss: 0.0381\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0374 - val_loss: 0.0373\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0367 - val_loss: 0.0372\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0356 - val_loss: 0.0352\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0351 - val_loss: 0.0355\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0347 - val_loss: 0.0357\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "MSE Test: 0.0647\n",
      "---------------------------------------------------------\n",
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0519 - val_loss: 0.0459\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0463 - val_loss: 0.0456\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0443 - val_loss: 0.0423\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0423 - val_loss: 0.0407\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0406 - val_loss: 0.0386\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0389 - val_loss: 0.0380\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0377 - val_loss: 0.0371\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0353 - val_loss: 0.0350\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0343 - val_loss: 0.0343\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0334 - val_loss: 0.0332\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0326 - val_loss: 0.0313\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0319 - val_loss: 0.0330\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0313 - val_loss: 0.0302\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0307 - val_loss: 0.0302\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0302 - val_loss: 0.0301\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0299 - val_loss: 0.0295\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0294 - val_loss: 0.0288\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0287 - val_loss: 0.0286\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0283 - val_loss: 0.0294\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "MSE Test: 0.0534\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# GloVe pretrained\n",
    "##################################################################################\n",
    "\n",
    "# valence\n",
    "model_NN2_valence_GloVe_pretrained_augmented, predictions_NN2_valence_GloVe_pretrained_augmented, MSE_NN2_valence_GloVe_pretrained_augmented = NN2(\n",
    "    X_train_GloVe_pretrained_augmented, y_train_valence_augmented, X_test_GloVe_pretrained, y_test_valence,\n",
    "    epochs_=20)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_NN2_arousal_GloVe_pretrained_augmented, predictions_NN2_arousal_GloVe_pretrained_augmented, MSE_NN2_arousal_GloVe_pretrained_augmented = NN2(\n",
    "    X_train_GloVe_pretrained_augmented, y_train_arousal_augmented, X_test_GloVe_pretrained, y_test_arousal,\n",
    "    epochs_=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_20784\\3301178310.py:29: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\morit\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "2724/2724 [==============================] - 7s 2ms/step - loss: 0.0628 - val_loss: 0.0589\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 5s 2ms/step - loss: 0.0591 - val_loss: 0.0574\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 5s 2ms/step - loss: 0.0586 - val_loss: 0.0584\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 5s 2ms/step - loss: 0.0585 - val_loss: 0.0571\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 4s 2ms/step - loss: 0.0583 - val_loss: 0.0579\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 4s 2ms/step - loss: 0.0581 - val_loss: 0.0570\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 4s 2ms/step - loss: 0.0579 - val_loss: 0.0581\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 4s 2ms/step - loss: 0.0579 - val_loss: 0.0571\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 4s 2ms/step - loss: 0.0578 - val_loss: 0.0570\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 6s 2ms/step - loss: 0.0578 - val_loss: 0.0571\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0577 - val_loss: 0.0568\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0577 - val_loss: 0.0567\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0576 - val_loss: 0.0570\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0575 - val_loss: 0.0570\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0575 - val_loss: 0.0572\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0574 - val_loss: 0.0573\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0574 - val_loss: 0.0567\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0572 - val_loss: 0.0563\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0573 - val_loss: 0.0572\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0572 - val_loss: 0.0568\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0584\n",
      "---------------------------------------------------------\n",
      "Epoch 1/20\n",
      "2724/2724 [==============================] - 9s 3ms/step - loss: 0.0557 - val_loss: 0.0500\n",
      "Epoch 2/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0507 - val_loss: 0.0502\n",
      "Epoch 3/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0500 - val_loss: 0.0510\n",
      "Epoch 4/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0497 - val_loss: 0.0489\n",
      "Epoch 5/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0496 - val_loss: 0.0486\n",
      "Epoch 6/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0491 - val_loss: 0.0494\n",
      "Epoch 7/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0491 - val_loss: 0.0487\n",
      "Epoch 8/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0488 - val_loss: 0.0495\n",
      "Epoch 9/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0488 - val_loss: 0.0493\n",
      "Epoch 10/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0487 - val_loss: 0.0488\n",
      "Epoch 11/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0486 - val_loss: 0.0491\n",
      "Epoch 12/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0485 - val_loss: 0.0492\n",
      "Epoch 13/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0483 - val_loss: 0.0484\n",
      "Epoch 14/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0481 - val_loss: 0.0478\n",
      "Epoch 15/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0480 - val_loss: 0.0490\n",
      "Epoch 16/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0480 - val_loss: 0.0481\n",
      "Epoch 17/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 18/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0478 - val_loss: 0.0492\n",
      "Epoch 19/20\n",
      "2724/2724 [==============================] - 7s 3ms/step - loss: 0.0477 - val_loss: 0.0489\n",
      "Epoch 20/20\n",
      "2724/2724 [==============================] - 8s 3ms/step - loss: 0.0476 - val_loss: 0.0517\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "MSE Test: 0.0521\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# BERT\n",
    "##################################################################################\n",
    "\n",
    "# valence\n",
    "model_NN2_valence_BERT_augmented, predictions_NN2_valence_BERT_augmented, MSE_NN2_valence_BERT_augmented = NN2(\n",
    "    X_train_BERT_augmented, y_train_valence_augmented, X_test_BERT, y_test_valence,\n",
    "    epochs_=20)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# arousal\n",
    "model_NN2_arousal_BERT_augmented, predictions_NN2_arousal_BERT_augmented, MSE_NN2_arousal_BERT_augmented = NN2(\n",
    "    X_train_BERT_augmented, y_train_arousal_augmented, X_test_BERT, y_test_arousal,\n",
    "    epochs_=20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpQWedUo7ZwdwngYdNiFEU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
